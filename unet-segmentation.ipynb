{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET SEGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arxiv Link: <a href=\"https://arxiv.org/abs/1505.04597\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>UNet is a fully convolutional network(FCN) that does image segmentation. Its goal is to predict each pixel's class.</li>\n",
    " \n",
    "<li>UNet is built upon the FCN and modified in a way that it yields better segmentation in medical imaging.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Architecture\n",
    "\n",
    "<img src=\"images/u-net-architecture.png\"/>\n",
    "\n",
    "<h3>UNet Architecture has 3 parts:</h3>\n",
    "<ol>\n",
    "    <li>The Contracting/Downsampling Path</li>\n",
    "    <li>Bottleneck</li>\n",
    "    <li>The Expanding/Upsampling Path</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Downsampling Path: </h3> \n",
    "<ol>\n",
    "    <li>It consists of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling.</li> \n",
    "    <li>At each downsampling step we double the number of feature channels.</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Upsampling Path: </h3> \n",
    "<ol>\n",
    "     <li> Every  step  in  the  expansive  path  consists  of  an  upsampling  of  the feature map followed by a 2x2 convolution (“up-convolution”), a concatenation with the correspondingly feature  map  from  the  downsampling  path,  and  two  3x3  convolutions,  each  followed by a ReLU.</li>\n",
    "</ol>\n",
    "\n",
    "<h3> Skip Connection: </h3>\n",
    "The skip connection from the downsampling path are concatenated with feature map during upsampling path. These skip connection provide local information to global information while upsampling.\n",
    "\n",
    "<h3> Final Layer: </h3>\n",
    "At the final layer a 1x1 convolution is used to map each feature vector to the desired number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Advantages\n",
    "<h3> Advantages: </h3>\n",
    "<ol>\n",
    "    <li>The UNet combines the location information from the downsampling path to finally obtain a general information combining localisation and context, which is necessary to predict a good segmentation map.</li>\n",
    "    <li>No Dense layer is used, so image sizes can be used.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset\n",
    "Link: <a href=\"https://www.kaggle.com/c/data-science-bowl-2018\">Data Science Bowl 2018</a>\n",
    "Find the nuclei in divergent images to advance medical discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## Seeding \\nseed = 2019\\nrandom.seed = seed\\nnp.random.seed = seed\\ntf.seed = seed'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Imports\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#Keras import\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import * \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from data_prep import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#Tensorboard for Visualization\n",
    "from keras.callbacks import TensorBoard \n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "#Import Unet Model\n",
    "from model import *\n",
    "\n",
    "\"\"\"\n",
    "## Seeding \n",
    "seed = 2019\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "tf.seed = seed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "K.set_session\n",
    "import tensorflow as tf\n",
    "#K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17678550320200779084\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 713032559271778000\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14476010037136017704\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15928269210\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12173038594571418730\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:0a:00.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#To check if model is using GPU or CPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import json\n",
    "with open('/Users/vasudevsharma/Desktop/axondeepseg-master-2/AxonDeepSeg/models/default_SEM_model_v1/config_network.json') as djson:\n",
    "    training_config = json.load(djson)\n",
    "print(training_config) \"\"\"\n",
    "# Example of network configuration for TEM data (small network trainable on a Titan X GPU card)\n",
    "training_config = {\n",
    "    \n",
    "# General parameters:    \n",
    "  \"n_classes\": 3,  # Number of classes. For this application, the number of classes should be set to **3** (i.e. axon pixel, myelin pixel, or background pixel).\n",
    "  \"thresholds\": [0, 0.2, 0.8],  # Thresholds for the 3-class classification problem. Do not modify.  \n",
    "  \"trainingset_patchsize\": 512,  # Patch size of the training set in pixels (note that the patches have the same size in both dimensions).  \n",
    "  \"trainingset\": \"TEM_3c_512\",  # Name of the training set.\n",
    "  \"batch_size\": 8,  # Batch size, i.e. the number of training patches used in one iteration of the training. Note that a larger batch size will take more memory.\n",
    "\n",
    "# Network architecture parameters:     \n",
    "  \"depth\": 4,  # Depth of the network (i.e. number of blocks of the U-net).\n",
    "  \"convolution_per_layer\": [2, 2, 2, 2],  # Number of convolution layers used at each block.\n",
    "  \"size_of_convolutions_per_layer\": [[5, 5], [3, 3], [3, 3], [3, 3]],  # Kernel size of each convolution layer of the network.\n",
    "  \"features_per_convolution\": [[[1, 16], [16, 16]], [[16, 32], [32, 32]], [[32, 64], [64, 64]], [[64, 128], [128, 128]]],  # Number of features of each convolution layer.\n",
    "  \"downsampling\": \"convolution\",  # Type of downsampling to use in the downsampling layers of the network. Option \"maxpooling\" for standard max pooling layer or option \"convolution\" for learned convolutional downsampling.\n",
    "  \"dropout\": 0.75,  # Dropout to use for the training. Note: In TensorFlow, the keep probability is used instead. For instance, setting this param. to 0.75 means that 75% of the neurons of the network will be kept (i.e. dropout of 25%).\n",
    "     \n",
    "# Learning rate parameters:    \n",
    "  \"learning_rate\": 0.01,  # Learning rate to use in the training.  \n",
    "  \"learning_rate_decay_activate\": True,  # Set to \"True\" to use a decay on the learning rate.  \n",
    "  \"learning_rate_decay_period\": 24000,  # Period of the learning rate decay, expressed in number of images (samples) seen.\n",
    "  \"learning_rate_decay_type\": \"polynomial\",  # Type of decay to use. An exponential decay will be used by default unless this param. is set to \"polynomial\" (to use a polynomial decay).\n",
    "  \"learning_rate_decay_rate\": 0.99,  # Rate of the decay to use for the exponential decay. This only applies when the user does not set the decay type to \"polynomial\".\n",
    "    \n",
    "# Batch normalization parameters:     \n",
    "  \"batch_norm_activate\": True,  # Set to \"True\" to use batch normalization during the training.\n",
    "  \"batch_norm_decay_decay_activate\": True,  # Set to \"True\" to activate an exponential decay for the batch normalization step of the training.  \n",
    "  \"batch_norm_decay_starting_decay\": 0.7,  # The starting decay value for the batch normalization. \n",
    "  \"batch_norm_decay_ending_decay\": 0.9,  # The ending decay value for the batch normalization.\n",
    "  \"batch_norm_decay_decay_period\": 16000,  # Period of the batch normalization decay, expressed in number of images (samples) seen.\n",
    "        \n",
    "# Weighted cost parameters:    \n",
    "  \"weighted_cost-activate\": True,  # Set to \"True\" to use weights based on the class in the cost function for the training.\n",
    "  \"weighted_cost-balanced_activate\": True,  # Set to \"True\" to use weights in the cost function to correct class imbalance. \n",
    "  \"weighted_cost-balanced_weights\": [1.1, 1, 1.3],  # Values of the weights for the class imbalance. Typically, larger weights are assigned to classes with less pixels to add more penalty in the cost function when there is a misclassification. Order of the classes in the weights list: background, myelin, axon.\n",
    "  \"weighted_cost-boundaries_sigma\": 2,  # Set to \"True\" to add weights to the boundaries (e.g. penalize more when misclassification happens in the axon-myelin interface).\n",
    "  \"weighted_cost-boundaries_activate\": False,  # Value to control the distribution of the boundary weights (if activated). \n",
    "    \n",
    "# Data augmentation parameters:\n",
    "  \"da-type\": \"all\",  # Type of data augmentation procedure. Option \"all\" applies all selected data augmentation transformations sequentially, while option \"random\" only applies one of the selected transformations (randomly) to the sample(s). List of available data augmentation transformations: 'random_rotation', 'noise_addition', 'elastic', 'shifting', 'rescaling' and 'flipping'. \n",
    "  \"da-0-shifting-activate\": True, \n",
    "  \"da-1-rescaling-activate\": False,\n",
    "  \"da-2-random_rotation-activate\": False,  \n",
    "  \"da-3-elastic-activate\": True, \n",
    "  \"da-4-flipping-activate\": True, \n",
    "  \"da-5-noise_addition-activate\": False\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Convolutional Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def upconv(x, n_out_chan, scope, \\n              w_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\\n              training_phase=True, activate_bn = True, bn_decay = 0.999):\\n   \\n    \\n    with tf.variable_scope(scope):\\n        if activate_bn == True:\\n            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \\n                                       activation_fn=tf.nn.relu, normalizer_fn=tf.contrib.layers.batch_norm,\\n                                       normalizer_params={'scale':True, 'is_training':training_phase,\\n                                                          'decay':bn_decay, 'scope':'bn'},\\n                                       weights_initializer = w_initializer, scope='convolution'\\n                                      )\\n        else:\\n            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \\n                                       activation_fn=tf.nn.relu, weights_initializer = w_initializer, scope='convolution'\\n                                      )\\n        \\n        tf.add_to_collection('activations',net)\\n        return net\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv_relu(x, filters , kernel_size , strides , activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999, keep_prob=1.0, ):\n",
    "    if activate_bn == True:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same', activation = activation, kernel_initializer = kernel_initializer)(x)\n",
    "            net = BatchNormalization(axis = 3, momentum = 1 - bn_decay)(net)\n",
    "            \n",
    "    else: \n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, activation = activation, kernel_initializer = kernel_initializer, padding = 'same')(net)\n",
    "            \n",
    "    net =  Dropout(rate = 1 - keep_prob)(net)\n",
    "            \n",
    "    return net \n",
    "\n",
    "   \n",
    "def downconv(x, filters , kernel_size = 5, strides = 2, activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999):\n",
    "    if activate_bn == True:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same',activation = activation, kernel_initializer = kernel_initializer)(x)\n",
    "            net = BatchNormalization(axis = 3, momentum = 1 - bn_decay)(net)\n",
    "\n",
    "    else:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, activation = activation, kernel_initializer = kernel_initializer, padding = 'same')(net)\n",
    "            \n",
    "    return net\n",
    "\n",
    "\"\"\"def upconv(x, n_out_chan, scope, \n",
    "              w_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "              training_phase=True, activate_bn = True, bn_decay = 0.999):\n",
    "   \n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        if activate_bn == True:\n",
    "            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \n",
    "                                       activation_fn=tf.nn.relu, normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                       normalizer_params={'scale':True, 'is_training':training_phase,\n",
    "                                                          'decay':bn_decay, 'scope':'bn'},\n",
    "                                       weights_initializer = w_initializer, scope='convolution'\n",
    "                                      )\n",
    "        else:\n",
    "            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \n",
    "                                       activation_fn=tf.nn.relu, weights_initializer = w_initializer, scope='convolution'\n",
    "                                      )\n",
    "        \n",
    "        tf.add_to_collection('activations',net)\n",
    "        return net\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    " model = uconv_net(training_config,  bn_updated_decay = None, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "def dice_myelin(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true[..., 1])\n",
    "    y_pred_f = K.flatten(y_pred[..., 1])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "def dice_axon(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true[..., 2])\n",
    "    y_pred_f = K.flatten(y_pred[..., 2])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"TEM_sample_dataset-{}\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "tensorboard = TensorBoard(log_dir = 'models/{}'.format(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'TEM_sample_dataset-2019-06-11 05:07:58'"
=======
       "'TEM_sample_dataset-2019-06-10 19:37:22'"
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=training_config['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 16) 6416        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512, 512, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 16) 6416        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 32) 4640        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256, 256, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 32) 9248        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 32) 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 256, 32) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 32) 25632       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 32) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 18496       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 64) 36928       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 64)   102464      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  73856       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  409728      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 128)  147584      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           dropout_6[0][0]                  \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 64) 36928       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 32) 128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           dropout_4[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 256, 32) 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 9248        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 256, 32) 128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 32) 0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 16) 2064        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 512, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 32) 0           dropout_2[0][0]                  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 512, 512, 16) 12816       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 512, 16) 64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 512, 512, 16) 6416        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 512, 16) 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "finalconv (Conv2D)              (None, 512, 512, 3)  51          dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,557,507\n",
      "Trainable params: 1,554,627\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\", dice_axon, dice_myelin, dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/vasha_local/axondeepseg/TEM_striatum/data/Train/'\n",
    "test_path = '/home/vasha_local/axondeepseg/TEM_striatum/data/Validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = training_config[\"n_classes\"]\n",
    "thresholds = training_config[\"thresholds\"]\n",
    "patch_size = training_config[\"trainingset_patchsize\"]\n",
    "\n",
    "batch_size = training_config[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = True # Boolean Value to indicate whether you want to use Data Augmentation or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flipping up-down\n",
      "flipping left-right\n",
      "('height shift: ', 0.158203125, ', width shift: ', 0.083984375)\n",
      "('height shift: ', 0.15234375, ', width shift: ', 0.048828125)\n"
     ]
    }
   ],
   "source": [
    "if(not data_aug):\n",
    "    data_gen_args = dict() \n",
    "else: \n",
    "    data_gen_args = dict(horizontal_flip = flipping()[1],\n",
    "                        vertical_flip = flipping()[0], \n",
    "                        rotation_range = random_rotation()[0], \n",
    "                        width_shift_range = shifting(patch_size, n_classes)[1],\n",
    "                        height_shift_range = shifting(patch_size, n_classes) [0]\n",
    "                        )\n",
    "\n",
    "#Data Augmentation Dictionary for Validation \n",
    "data_gen_args_valid = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'horizontal_flip': True,\n",
       " 'vertical_flip': True,\n",
       " 'rotation_range': 43.73224759795209,\n",
       " 'width_shift_range': 0.083984375,\n",
       " 'height_shift_range': 0.15234375}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check of augmented data dictionary\n",
    "data_gen_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "train_gen = Generator(batch_size,'/home/vasha_local/axondeepseg/TEM_striatum/data/Train/','images','masks',data_gen_args,save_to_dir = None)\n",
    "valid_gen = Generator(batch_size, '/home/vasha_local/axondeepseg/TEM_striatum/data/Validation/','images','masks', data_gen_args_valid,save_to_dir = None)                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the checkpoint in the /output folder\n",
    "filepath_acc = \"models/\"+Name+\"/axondeepseg-best_acc.hdf5\"\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "checkpoint_acc = ModelCheckpoint(filepath_acc,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "\n",
    "# Save the checkpoint in the /output folder\n",
    "filepath_loss = \"models/\"+Name+\"/axondeepseg-best_loss.hdf5\"\n",
    "\n",
    "# Keep only a single checkpoint, the best over test loss.\n",
    "checkpoint_loss = ModelCheckpoint(filepath_loss,\n",
    "                            monitor='val_loss',\n",
    "                            verbose=0,\n",
    "                            save_best_only=True,\n",
    "                            mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps =150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
<<<<<<< HEAD
      "Epoch 1/100\n",
=======
      "Epoch 1/1000\n",
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
      "Found 16 images belonging to 1 classes.\n",
      "Found 36 images belonging to 1 classes.\n",
      "Found 16 images belonging to 1 classes.\n",
      "Found 36 images belonging to 1 classes.\n",
<<<<<<< HEAD
      "4/4 [==============================] - 8s 2s/step - loss: 1.2135 - acc: 0.5563 - dice_axon: 0.0370 - dice_myelin: 0.0654 - dice_coef: 0.3689 - val_loss: 14.1181 - val_acc: 0.1069 - val_dice_axon: 0.0274 - val_dice_myelin: 0.1850 - val_dice_coef: 0.1057\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.9102 - acc: 0.8624 - dice_axon: 0.0364 - dice_myelin: 0.0775 - dice_coef: 0.4484 - val_loss: 7.1896 - val_acc: 0.4006 - val_dice_axon: 0.1288 - val_dice_myelin: 0.1652 - val_dice_coef: 0.2526\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.7412 - acc: 0.9093 - dice_axon: 0.0448 - dice_myelin: 0.1164 - dice_coef: 0.5220 - val_loss: 3.5899 - val_acc: 0.6489 - val_dice_axon: 0.0976 - val_dice_myelin: 0.2197 - val_dice_coef: 0.4223\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.5980 - acc: 0.9310 - dice_axon: 0.0450 - dice_myelin: 0.1286 - dice_coef: 0.6017 - val_loss: 0.7681 - val_acc: 0.8495 - val_dice_axon: 0.0824 - val_dice_myelin: 0.2547 - val_dice_coef: 0.5937\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.4363 - acc: 0.9602 - dice_axon: 0.0406 - dice_myelin: 0.1130 - dice_coef: 0.6888 - val_loss: 0.7434 - val_acc: 0.8384 - val_dice_axon: 0.1014 - val_dice_myelin: 0.2275 - val_dice_coef: 0.6621\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.3228 - acc: 0.9552 - dice_axon: 0.0450 - dice_myelin: 0.1324 - dice_coef: 0.7656 - val_loss: 0.4549 - val_acc: 0.8415 - val_dice_axon: 0.1181 - val_dice_myelin: 0.2771 - val_dice_coef: 0.7375\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.2682 - acc: 0.9457 - dice_axon: 0.0455 - dice_myelin: 0.1868 - dice_coef: 0.8300 - val_loss: 0.5678 - val_acc: 0.8450 - val_dice_axon: 0.0686 - val_dice_myelin: 0.3267 - val_dice_coef: 0.7816\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 4s 903ms/step - loss: 0.1976 - acc: 0.9596 - dice_axon: 0.0548 - dice_myelin: 0.2270 - dice_coef: 0.8831 - val_loss: 0.5127 - val_acc: 0.8478 - val_dice_axon: 0.0742 - val_dice_myelin: 0.3118 - val_dice_coef: 0.8099\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 3s 848ms/step - loss: 0.1695 - acc: 0.9584 - dice_axon: 0.0777 - dice_myelin: 0.2827 - dice_coef: 0.9094 - val_loss: 0.5231 - val_acc: 0.8396 - val_dice_axon: 0.0668 - val_dice_myelin: 0.2835 - val_dice_coef: 0.8218\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 3s 816ms/step - loss: 0.1452 - acc: 0.9614 - dice_axon: 0.0604 - dice_myelin: 0.2940 - dice_coef: 0.9280 - val_loss: 0.6993 - val_acc: 0.8534 - val_dice_axon: 0.0593 - val_dice_myelin: 0.4215 - val_dice_coef: 0.8329\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.1415 - acc: 0.9563 - dice_axon: 0.0749 - dice_myelin: 0.3333 - dice_coef: 0.9315 - val_loss: 0.4705 - val_acc: 0.8561 - val_dice_axon: 0.0781 - val_dice_myelin: 0.3400 - val_dice_coef: 0.8355\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 3s 807ms/step - loss: 0.1228 - acc: 0.9583 - dice_axon: 0.1412 - dice_myelin: 0.2652 - dice_coef: 0.9384 - val_loss: 0.6236 - val_acc: 0.8372 - val_dice_axon: 0.0632 - val_dice_myelin: 0.1554 - val_dice_coef: 0.8268\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 3s 840ms/step - loss: 0.1767 - acc: 0.9414 - dice_axon: 0.1181 - dice_myelin: 0.3008 - dice_coef: 0.9210 - val_loss: 0.5594 - val_acc: 0.8713 - val_dice_axon: 0.1979 - val_dice_myelin: 0.4972 - val_dice_coef: 0.8363\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.1268 - acc: 0.9652 - dice_axon: 0.0900 - dice_myelin: 0.3009 - dice_coef: 0.9370 - val_loss: 0.5727 - val_acc: 0.8375 - val_dice_axon: 0.0755 - val_dice_myelin: 0.2364 - val_dice_coef: 0.8352\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 3s 801ms/step - loss: 0.1505 - acc: 0.9545 - dice_axon: 0.0818 - dice_myelin: 0.2483 - dice_coef: 0.9421 - val_loss: 0.5359 - val_acc: 0.8370 - val_dice_axon: 0.1234 - val_dice_myelin: 0.1810 - val_dice_coef: 0.8356\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 4s 983ms/step - loss: 0.1226 - acc: 0.9575 - dice_axon: 0.1416 - dice_myelin: 0.3548 - dice_coef: 0.9402 - val_loss: 0.3969 - val_acc: 0.8543 - val_dice_axon: 0.2406 - val_dice_myelin: 0.3326 - val_dice_coef: 0.8458\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 0.0919 - acc: 0.9697 - dice_axon: 0.1736 - dice_myelin: 0.2860 - dice_coef: 0.9448 - val_loss: 0.4368 - val_acc: 0.8455 - val_dice_axon: 0.2596 - val_dice_myelin: 0.2705 - val_dice_coef: 0.8427\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 4s 878ms/step - loss: 0.1482 - acc: 0.9409 - dice_axon: 0.2902 - dice_myelin: 0.3022 - dice_coef: 0.9285 - val_loss: 0.3732 - val_acc: 0.8569 - val_dice_axon: 0.3267 - val_dice_myelin: 0.3735 - val_dice_coef: 0.8470\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 3s 843ms/step - loss: 0.0927 - acc: 0.9676 - dice_axon: 0.2996 - dice_myelin: 0.3902 - dice_coef: 0.9429 - val_loss: 0.4236 - val_acc: 0.8447 - val_dice_axon: 0.1587 - val_dice_myelin: 0.3466 - val_dice_coef: 0.8447\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 3s 807ms/step - loss: 0.1033 - acc: 0.9617 - dice_axon: 0.1971 - dice_myelin: 0.3443 - dice_coef: 0.9464 - val_loss: 0.3192 - val_acc: 0.8762 - val_dice_axon: 0.3897 - val_dice_myelin: 0.4069 - val_dice_coef: 0.8608\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.0981 - acc: 0.9595 - dice_axon: 0.3158 - dice_myelin: 0.3657 - dice_coef: 0.9459 - val_loss: 0.3064 - val_acc: 0.8878 - val_dice_axon: 0.4492 - val_dice_myelin: 0.4401 - val_dice_coef: 0.8632\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 3s 779ms/step - loss: 0.0864 - acc: 0.9667 - dice_axon: 0.3838 - dice_myelin: 0.3805 - dice_coef: 0.9498 - val_loss: 0.2824 - val_acc: 0.8955 - val_dice_axon: 0.4505 - val_dice_myelin: 0.4933 - val_dice_coef: 0.8681\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.0939 - acc: 0.9637 - dice_axon: 0.3284 - dice_myelin: 0.3660 - dice_coef: 0.9493 - val_loss: 0.2600 - val_acc: 0.9040 - val_dice_axon: 0.4287 - val_dice_myelin: 0.4742 - val_dice_coef: 0.8701\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 3s 823ms/step - loss: 0.0994 - acc: 0.9596 - dice_axon: 0.3084 - dice_myelin: 0.3403 - dice_coef: 0.9449 - val_loss: 0.2921 - val_acc: 0.8777 - val_dice_axon: 0.4096 - val_dice_myelin: 0.4056 - val_dice_coef: 0.8659\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 0.0753 - acc: 0.9715 - dice_axon: 0.4115 - dice_myelin: 0.4481 - dice_coef: 0.9550 - val_loss: 0.3145 - val_acc: 0.8868 - val_dice_axon: 0.4577 - val_dice_myelin: 0.4497 - val_dice_coef: 0.8704\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0996 - acc: 0.9640 - dice_axon: 0.3686 - dice_myelin: 0.4164 - dice_coef: 0.9531 - val_loss: 0.3062 - val_acc: 0.8859 - val_dice_axon: 0.4781 - val_dice_myelin: 0.4118 - val_dice_coef: 0.8717\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 0.0757 - acc: 0.9723 - dice_axon: 0.4317 - dice_myelin: 0.4638 - dice_coef: 0.9568 - val_loss: 0.4114 - val_acc: 0.8801 - val_dice_axon: 0.4322 - val_dice_myelin: 0.3648 - val_dice_coef: 0.8669\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 3s 868ms/step - loss: 0.0826 - acc: 0.9707 - dice_axon: 0.5139 - dice_myelin: 0.5198 - dice_coef: 0.9567 - val_loss: 0.7715 - val_acc: 0.8225 - val_dice_axon: 0.0717 - val_dice_myelin: 0.1659 - val_dice_coef: 0.8142\n"
=======
      "150/150 [==============================] - 89s 592ms/step - loss: 0.6222 - acc: 0.9159 - dice_axon: 0.0963 - dice_myelin: 0.1316 - dice_coef: 0.5891 - val_loss: 0.3437 - val_acc: 0.9043 - val_dice_axon: 0.3792 - val_dice_myelin: 0.3571 - val_dice_coef: 0.7932\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 85s 567ms/step - loss: 0.1648 - acc: 0.9791 - dice_axon: 0.2796 - dice_myelin: 0.3197 - dice_coef: 0.8792 - val_loss: 0.3363 - val_acc: 0.8899 - val_dice_axon: 0.5049 - val_dice_myelin: 0.3567 - val_dice_coef: 0.8677\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 85s 567ms/step - loss: 0.0758 - acc: 0.9833 - dice_axon: 0.4741 - dice_myelin: 0.4766 - dice_coef: 0.9489 - val_loss: 0.2189 - val_acc: 0.9397 - val_dice_axon: 0.6816 - val_dice_myelin: 0.6076 - val_dice_coef: 0.9040\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 87s 582ms/step - loss: 0.0528 - acc: 0.9856 - dice_axon: 0.5893 - dice_myelin: 0.5585 - dice_coef: 0.9663 - val_loss: 0.1937 - val_acc: 0.9439 - val_dice_axon: 0.7159 - val_dice_myelin: 0.6420 - val_dice_coef: 0.9197\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0499 - acc: 0.9854 - dice_axon: 0.6425 - dice_myelin: 0.5789 - dice_coef: 0.9713 - val_loss: 0.2615 - val_acc: 0.9176 - val_dice_axon: 0.5485 - val_dice_myelin: 0.5742 - val_dice_coef: 0.9030\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 85s 565ms/step - loss: 0.0505 - acc: 0.9841 - dice_axon: 0.6421 - dice_myelin: 0.5818 - dice_coef: 0.9715 - val_loss: 0.2943 - val_acc: 0.9191 - val_dice_axon: 0.5810 - val_dice_myelin: 0.5617 - val_dice_coef: 0.9052\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 89s 590ms/step - loss: 0.0384 - acc: 0.9870 - dice_axon: 0.7078 - dice_myelin: 0.6239 - dice_coef: 0.9775 - val_loss: 0.1504 - val_acc: 0.9485 - val_dice_axon: 0.7589 - val_dice_myelin: 0.6803 - val_dice_coef: 0.9317\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 85s 568ms/step - loss: 0.0364 - acc: 0.9873 - dice_axon: 0.7382 - dice_myelin: 0.6496 - dice_coef: 0.9794 - val_loss: 0.1440 - val_acc: 0.9469 - val_dice_axon: 0.7567 - val_dice_myelin: 0.6717 - val_dice_coef: 0.9327\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 90s 599ms/step - loss: 0.0351 - acc: 0.9880 - dice_axon: 0.7457 - dice_myelin: 0.6481 - dice_coef: 0.9805 - val_loss: 0.1291 - val_acc: 0.9517 - val_dice_axon: 0.7714 - val_dice_myelin: 0.6979 - val_dice_coef: 0.9359\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 86s 572ms/step - loss: 0.0332 - acc: 0.9880 - dice_axon: 0.7643 - dice_myelin: 0.6613 - dice_coef: 0.9813 - val_loss: 0.1212 - val_acc: 0.9549 - val_dice_axon: 0.7789 - val_dice_myelin: 0.7091 - val_dice_coef: 0.9393\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0352 - acc: 0.9872 - dice_axon: 0.7644 - dice_myelin: 0.6618 - dice_coef: 0.9804 - val_loss: 0.1557 - val_acc: 0.9477 - val_dice_axon: 0.7696 - val_dice_myelin: 0.6810 - val_dice_coef: 0.9356\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 87s 581ms/step - loss: 0.0357 - acc: 0.9875 - dice_axon: 0.7683 - dice_myelin: 0.6606 - dice_coef: 0.9810 - val_loss: 0.1361 - val_acc: 0.9512 - val_dice_axon: 0.7838 - val_dice_myelin: 0.7077 - val_dice_coef: 0.9387\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 88s 588ms/step - loss: 0.0293 - acc: 0.9890 - dice_axon: 0.7940 - dice_myelin: 0.6907 - dice_coef: 0.9834 - val_loss: 0.1455 - val_acc: 0.9503 - val_dice_axon: 0.7547 - val_dice_myelin: 0.6868 - val_dice_coef: 0.9361\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 85s 568ms/step - loss: 0.0302 - acc: 0.9889 - dice_axon: 0.7903 - dice_myelin: 0.6872 - dice_coef: 0.9834 - val_loss: 0.1877 - val_acc: 0.9391 - val_dice_axon: 0.6644 - val_dice_myelin: 0.6737 - val_dice_coef: 0.9224\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 88s 584ms/step - loss: 0.0381 - acc: 0.9867 - dice_axon: 0.7559 - dice_myelin: 0.6587 - dice_coef: 0.9806 - val_loss: 0.1404 - val_acc: 0.9499 - val_dice_axon: 0.7872 - val_dice_myelin: 0.6920 - val_dice_coef: 0.9390\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 89s 593ms/step - loss: 0.0354 - acc: 0.9877 - dice_axon: 0.7802 - dice_myelin: 0.6743 - dice_coef: 0.9817 - val_loss: 0.2071 - val_acc: 0.9380 - val_dice_axon: 0.7085 - val_dice_myelin: 0.6352 - val_dice_coef: 0.9231\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 85s 565ms/step - loss: 0.0276 - acc: 0.9895 - dice_axon: 0.8068 - dice_myelin: 0.7067 - dice_coef: 0.9842 - val_loss: 0.1396 - val_acc: 0.9516 - val_dice_axon: 0.7729 - val_dice_myelin: 0.6920 - val_dice_coef: 0.9358\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0256 - acc: 0.9901 - dice_axon: 0.8181 - dice_myelin: 0.7187 - dice_coef: 0.9852 - val_loss: 0.3190 - val_acc: 0.9235 - val_dice_axon: 0.6521 - val_dice_myelin: 0.5965 - val_dice_coef: 0.9128\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 87s 579ms/step - loss: 0.0338 - acc: 0.9880 - dice_axon: 0.7954 - dice_myelin: 0.6849 - dice_coef: 0.9825 - val_loss: 0.1432 - val_acc: 0.9500 - val_dice_axon: 0.7744 - val_dice_myelin: 0.6958 - val_dice_coef: 0.9374\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 87s 580ms/step - loss: 0.0276 - acc: 0.9896 - dice_axon: 0.8177 - dice_myelin: 0.7169 - dice_coef: 0.9846 - val_loss: 0.2512 - val_acc: 0.9317 - val_dice_axon: 0.6993 - val_dice_myelin: 0.6258 - val_dice_coef: 0.9203\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 84s 562ms/step - loss: 0.0264 - acc: 0.9902 - dice_axon: 0.8229 - dice_myelin: 0.7234 - dice_coef: 0.9856 - val_loss: 0.3123 - val_acc: 0.9255 - val_dice_axon: 0.6690 - val_dice_myelin: 0.5940 - val_dice_coef: 0.9150\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 85s 563ms/step - loss: 0.0272 - acc: 0.9901 - dice_axon: 0.8210 - dice_myelin: 0.7241 - dice_coef: 0.9852 - val_loss: 0.1458 - val_acc: 0.9538 - val_dice_axon: 0.7820 - val_dice_myelin: 0.7223 - val_dice_coef: 0.9412\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0277 - acc: 0.9894 - dice_axon: 0.8182 - dice_myelin: 0.7172 - dice_coef: 0.9846 - val_loss: 0.1804 - val_acc: 0.9458 - val_dice_axon: 0.7801 - val_dice_myelin: 0.6963 - val_dice_coef: 0.9372\n",
      "Epoch 24/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0328 - acc: 0.9886 - dice_axon: 0.7992 - dice_myelin: 0.6966 - dice_coef: 0.9834 - val_loss: 0.1517 - val_acc: 0.9510 - val_dice_axon: 0.7644 - val_dice_myelin: 0.7017 - val_dice_coef: 0.9360\n",
      "Epoch 25/1000\n",
      "150/150 [==============================] - 90s 600ms/step - loss: 0.0246 - acc: 0.9906 - dice_axon: 0.8281 - dice_myelin: 0.7340 - dice_coef: 0.9861 - val_loss: 0.1472 - val_acc: 0.9500 - val_dice_axon: 0.7838 - val_dice_myelin: 0.6931 - val_dice_coef: 0.9394\n",
      "Epoch 26/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0256 - acc: 0.9905 - dice_axon: 0.8278 - dice_myelin: 0.7274 - dice_coef: 0.9860 - val_loss: 0.1469 - val_acc: 0.9532 - val_dice_axon: 0.7875 - val_dice_myelin: 0.7290 - val_dice_coef: 0.9444\n",
      "Epoch 27/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0242 - acc: 0.9906 - dice_axon: 0.8338 - dice_myelin: 0.7372 - dice_coef: 0.9863 - val_loss: 0.1425 - val_acc: 0.9506 - val_dice_axon: 0.7997 - val_dice_myelin: 0.7093 - val_dice_coef: 0.9407\n",
      "Epoch 28/1000\n"
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 29/100\n",
      "4/4 [==============================] - 4s 901ms/step - loss: 0.0665 - acc: 0.9749 - dice_axon: 0.4357 - dice_myelin: 0.4449 - dice_coef: 0.9607 - val_loss: 0.3433 - val_acc: 0.8667 - val_dice_axon: 0.3800 - val_dice_myelin: 0.3484 - val_dice_coef: 0.8644\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 3s 803ms/step - loss: 0.0807 - acc: 0.9675 - dice_axon: 0.3672 - dice_myelin: 0.4339 - dice_coef: 0.9570 - val_loss: 0.3081 - val_acc: 0.8887 - val_dice_axon: 0.5049 - val_dice_myelin: 0.3922 - val_dice_coef: 0.8774\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0770 - acc: 0.9717 - dice_axon: 0.5043 - dice_myelin: 0.4950 - dice_coef: 0.9603 - val_loss: 0.3956 - val_acc: 0.8782 - val_dice_axon: 0.3634 - val_dice_myelin: 0.4020 - val_dice_coef: 0.8681\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 3s 872ms/step - loss: 0.0765 - acc: 0.9733 - dice_axon: 0.4987 - dice_myelin: 0.4555 - dice_coef: 0.9625 - val_loss: 0.4533 - val_acc: 0.8684 - val_dice_axon: 0.4616 - val_dice_myelin: 0.2861 - val_dice_coef: 0.8635\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 3s 834ms/step - loss: 0.0589 - acc: 0.9787 - dice_axon: 0.5404 - dice_myelin: 0.5343 - dice_coef: 0.9668 - val_loss: 0.2578 - val_acc: 0.9037 - val_dice_axon: 0.4982 - val_dice_myelin: 0.5009 - val_dice_coef: 0.8849\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 3s 836ms/step - loss: 0.0662 - acc: 0.9747 - dice_axon: 0.4901 - dice_myelin: 0.4907 - dice_coef: 0.9626 - val_loss: 0.2436 - val_acc: 0.9091 - val_dice_axon: 0.4850 - val_dice_myelin: 0.5148 - val_dice_coef: 0.8882\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 3s 824ms/step - loss: 0.0806 - acc: 0.9700 - dice_axon: 0.4620 - dice_myelin: 0.4342 - dice_coef: 0.9576 - val_loss: 0.2145 - val_acc: 0.9193 - val_dice_axon: 0.5617 - val_dice_myelin: 0.5698 - val_dice_coef: 0.8917\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0975 - acc: 0.9612 - dice_axon: 0.4638 - dice_myelin: 0.3679 - dice_coef: 0.9539 - val_loss: 0.5317 - val_acc: 0.8442 - val_dice_axon: 0.1847 - val_dice_myelin: 0.2063 - val_dice_coef: 0.8474\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 3s 864ms/step - loss: 0.0592 - acc: 0.9788 - dice_axon: 0.5055 - dice_myelin: 0.4692 - dice_coef: 0.9642 - val_loss: 0.2383 - val_acc: 0.9085 - val_dice_axon: 0.5248 - val_dice_myelin: 0.5122 - val_dice_coef: 0.8846\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 4s 884ms/step - loss: 0.0961 - acc: 0.9630 - dice_axon: 0.4641 - dice_myelin: 0.4420 - dice_coef: 0.9501 - val_loss: 0.2353 - val_acc: 0.9122 - val_dice_axon: 0.5252 - val_dice_myelin: 0.5630 - val_dice_coef: 0.8865\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 3s 833ms/step - loss: 0.0826 - acc: 0.9686 - dice_axon: 0.4635 - dice_myelin: 0.4218 - dice_coef: 0.9544 - val_loss: 0.3720 - val_acc: 0.8618 - val_dice_axon: 0.3839 - val_dice_myelin: 0.3176 - val_dice_coef: 0.8641\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0641 - acc: 0.9760 - dice_axon: 0.5221 - dice_myelin: 0.4804 - dice_coef: 0.9633 - val_loss: 0.5647 - val_acc: 0.8444 - val_dice_axon: 0.0851 - val_dice_myelin: 0.2589 - val_dice_coef: 0.8454\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0772 - acc: 0.9725 - dice_axon: 0.5469 - dice_myelin: 0.5196 - dice_coef: 0.9625 - val_loss: 0.2805 - val_acc: 0.9050 - val_dice_axon: 0.5282 - val_dice_myelin: 0.5570 - val_dice_coef: 0.8821\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 3s 844ms/step - loss: 0.0868 - acc: 0.9672 - dice_axon: 0.4911 - dice_myelin: 0.4132 - dice_coef: 0.9560 - val_loss: 0.2733 - val_acc: 0.8955 - val_dice_axon: 0.5044 - val_dice_myelin: 0.4388 - val_dice_coef: 0.8788\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 0.0494 - acc: 0.9831 - dice_axon: 0.5097 - dice_myelin: 0.4390 - dice_coef: 0.9687 - val_loss: 0.2564 - val_acc: 0.8930 - val_dice_axon: 0.5196 - val_dice_myelin: 0.4285 - val_dice_coef: 0.8765\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 4s 876ms/step - loss: 0.0676 - acc: 0.9729 - dice_axon: 0.4872 - dice_myelin: 0.4332 - dice_coef: 0.9629 - val_loss: 0.2717 - val_acc: 0.8994 - val_dice_axon: 0.5522 - val_dice_myelin: 0.4644 - val_dice_coef: 0.8838\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 0.0836 - acc: 0.9685 - dice_axon: 0.5758 - dice_myelin: 0.4899 - dice_coef: 0.9598 - val_loss: 0.3323 - val_acc: 0.8948 - val_dice_axon: 0.4272 - val_dice_myelin: 0.4614 - val_dice_coef: 0.8794\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0829 - acc: 0.9674 - dice_axon: 0.5123 - dice_myelin: 0.5093 - dice_coef: 0.9538 - val_loss: 0.2448 - val_acc: 0.9153 - val_dice_axon: 0.5674 - val_dice_myelin: 0.5589 - val_dice_coef: 0.8946\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 0.0861 - acc: 0.9649 - dice_axon: 0.4763 - dice_myelin: 0.4262 - dice_coef: 0.9544 - val_loss: 0.5705 - val_acc: 0.8417 - val_dice_axon: 0.1505 - val_dice_myelin: 0.1927 - val_dice_coef: 0.8459\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.0381 - acc: 0.9874 - dice_axon: 0.5730 - dice_myelin: 0.4259 - dice_coef: 0.9770 - val_loss: 0.3631 - val_acc: 0.8738 - val_dice_axon: 0.5201 - val_dice_myelin: 0.3458 - val_dice_coef: 0.8717\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 0.1080 - acc: 0.9645 - dice_axon: 0.5130 - dice_myelin: 0.4125 - dice_coef: 0.9581 - val_loss: 0.3094 - val_acc: 0.9176 - val_dice_axon: 0.5822 - val_dice_myelin: 0.5500 - val_dice_coef: 0.8972\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 3s 859ms/step - loss: 0.0981 - acc: 0.9595 - dice_axon: 0.4804 - dice_myelin: 0.4280 - dice_coef: 0.9506 - val_loss: 0.3790 - val_acc: 0.8694 - val_dice_axon: 0.4125 - val_dice_myelin: 0.3429 - val_dice_coef: 0.8689\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0776 - acc: 0.9712 - dice_axon: 0.5398 - dice_myelin: 0.5404 - dice_coef: 0.9575 - val_loss: 0.2390 - val_acc: 0.9152 - val_dice_axon: 0.5475 - val_dice_myelin: 0.5753 - val_dice_coef: 0.8944\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 0.0863 - acc: 0.9690 - dice_axon: 0.4647 - dice_myelin: 0.4422 - dice_coef: 0.9563 - val_loss: 0.3703 - val_acc: 0.8749 - val_dice_axon: 0.4452 - val_dice_myelin: 0.4333 - val_dice_coef: 0.8624\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 3s 841ms/step - loss: 0.0655 - acc: 0.9771 - dice_axon: 0.4232 - dice_myelin: 0.4219 - dice_coef: 0.9670 - val_loss: 0.5254 - val_acc: 0.8436 - val_dice_axon: 0.1357 - val_dice_myelin: 0.2107 - val_dice_coef: 0.8483\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 4s 882ms/step - loss: 0.0864 - acc: 0.9676 - dice_axon: 0.3793 - dice_myelin: 0.4345 - dice_coef: 0.9610 - val_loss: 0.2519 - val_acc: 0.9132 - val_dice_axon: 0.5495 - val_dice_myelin: 0.5654 - val_dice_coef: 0.8926\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.0871 - acc: 0.9674 - dice_axon: 0.4762 - dice_myelin: 0.4824 - dice_coef: 0.9562 - val_loss: 0.2536 - val_acc: 0.9203 - val_dice_axon: 0.5437 - val_dice_myelin: 0.6022 - val_dice_coef: 0.8947\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 4s 981ms/step - loss: 0.0769 - acc: 0.9714 - dice_axon: 0.5083 - dice_myelin: 0.5097 - dice_coef: 0.9587 - val_loss: 0.2367 - val_acc: 0.9134 - val_dice_axon: 0.5350 - val_dice_myelin: 0.5571 - val_dice_coef: 0.8837\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 3s 858ms/step - loss: 0.0511 - acc: 0.9818 - dice_axon: 0.5276 - dice_myelin: 0.4045 - dice_coef: 0.9701 - val_loss: 0.2946 - val_acc: 0.8854 - val_dice_axon: 0.5784 - val_dice_myelin: 0.3721 - val_dice_coef: 0.8796\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 4s 876ms/step - loss: 0.1199 - acc: 0.9552 - dice_axon: 0.4702 - dice_myelin: 0.4483 - dice_coef: 0.9486 - val_loss: 0.3841 - val_acc: 0.8767 - val_dice_axon: 0.2425 - val_dice_myelin: 0.4688 - val_dice_coef: 0.8689\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 3s 873ms/step - loss: 0.0737 - acc: 0.9715 - dice_axon: 0.4907 - dice_myelin: 0.4776 - dice_coef: 0.9581 - val_loss: 0.2391 - val_acc: 0.9165 - val_dice_axon: 0.5443 - val_dice_myelin: 0.5403 - val_dice_coef: 0.8949\n"
=======
      "150/150 [==============================] - 93s 620ms/step - loss: 0.0231 - acc: 0.9909 - dice_axon: 0.8357 - dice_myelin: 0.7430 - dice_coef: 0.9867 - val_loss: 0.1351 - val_acc: 0.9516 - val_dice_axon: 0.7920 - val_dice_myelin: 0.7099 - val_dice_coef: 0.9425\n",
      "Epoch 29/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0254 - acc: 0.9905 - dice_axon: 0.8318 - dice_myelin: 0.7391 - dice_coef: 0.9862 - val_loss: 0.1829 - val_acc: 0.9450 - val_dice_axon: 0.7221 - val_dice_myelin: 0.7071 - val_dice_coef: 0.9332\n",
      "Epoch 30/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0335 - acc: 0.9880 - dice_axon: 0.7979 - dice_myelin: 0.6964 - dice_coef: 0.9826 - val_loss: 0.1984 - val_acc: 0.9373 - val_dice_axon: 0.6913 - val_dice_myelin: 0.6149 - val_dice_coef: 0.9218\n",
      "Epoch 31/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0324 - acc: 0.9889 - dice_axon: 0.8008 - dice_myelin: 0.6988 - dice_coef: 0.9836 - val_loss: 0.1445 - val_acc: 0.9526 - val_dice_axon: 0.7963 - val_dice_myelin: 0.7207 - val_dice_coef: 0.9406\n",
      "Epoch 32/1000\n",
      "150/150 [==============================] - 93s 623ms/step - loss: 0.0325 - acc: 0.9889 - dice_axon: 0.8141 - dice_myelin: 0.7131 - dice_coef: 0.9839 - val_loss: 0.2760 - val_acc: 0.9268 - val_dice_axon: 0.6402 - val_dice_myelin: 0.6162 - val_dice_coef: 0.9136\n",
      "Epoch 33/1000\n",
      "150/150 [==============================] - 93s 620ms/step - loss: 0.0244 - acc: 0.9908 - dice_axon: 0.8361 - dice_myelin: 0.7410 - dice_coef: 0.9863 - val_loss: 0.1390 - val_acc: 0.9546 - val_dice_axon: 0.7967 - val_dice_myelin: 0.7384 - val_dice_coef: 0.9440\n",
      "Epoch 34/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0217 - acc: 0.9915 - dice_axon: 0.8464 - dice_myelin: 0.7512 - dice_coef: 0.9875 - val_loss: 0.1518 - val_acc: 0.9536 - val_dice_axon: 0.7887 - val_dice_myelin: 0.7225 - val_dice_coef: 0.9413\n",
      "Epoch 35/1000\n",
      "150/150 [==============================] - 93s 623ms/step - loss: 0.0279 - acc: 0.9904 - dice_axon: 0.8373 - dice_myelin: 0.7481 - dice_coef: 0.9860 - val_loss: 0.1645 - val_acc: 0.9503 - val_dice_axon: 0.7663 - val_dice_myelin: 0.7154 - val_dice_coef: 0.9377\n",
      "Epoch 36/1000\n",
      "150/150 [==============================] - 92s 617ms/step - loss: 0.0259 - acc: 0.9909 - dice_axon: 0.8404 - dice_myelin: 0.7482 - dice_coef: 0.9865 - val_loss: 0.1558 - val_acc: 0.9502 - val_dice_axon: 0.7721 - val_dice_myelin: 0.7145 - val_dice_coef: 0.9388\n",
      "Epoch 37/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0246 - acc: 0.9911 - dice_axon: 0.8416 - dice_myelin: 0.7545 - dice_coef: 0.9868 - val_loss: 0.1315 - val_acc: 0.9555 - val_dice_axon: 0.8002 - val_dice_myelin: 0.7366 - val_dice_coef: 0.9458\n",
      "Epoch 38/1000\n",
      "150/150 [==============================] - 91s 610ms/step - loss: 0.0211 - acc: 0.9916 - dice_axon: 0.8515 - dice_myelin: 0.7647 - dice_coef: 0.9877 - val_loss: 0.1555 - val_acc: 0.9523 - val_dice_axon: 0.7773 - val_dice_myelin: 0.7241 - val_dice_coef: 0.9416\n",
      "Epoch 39/1000\n",
      "150/150 [==============================] - 94s 627ms/step - loss: 0.0260 - acc: 0.9912 - dice_axon: 0.8465 - dice_myelin: 0.7650 - dice_coef: 0.9870 - val_loss: 0.1344 - val_acc: 0.9566 - val_dice_axon: 0.7765 - val_dice_myelin: 0.7606 - val_dice_coef: 0.9448\n",
      "Epoch 40/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0235 - acc: 0.9916 - dice_axon: 0.8539 - dice_myelin: 0.7678 - dice_coef: 0.9876 - val_loss: 0.1421 - val_acc: 0.9559 - val_dice_axon: 0.8007 - val_dice_myelin: 0.7585 - val_dice_coef: 0.9471\n",
      "Epoch 41/1000\n",
      "150/150 [==============================] - 93s 621ms/step - loss: 0.0227 - acc: 0.9919 - dice_axon: 0.8553 - dice_myelin: 0.7703 - dice_coef: 0.9880 - val_loss: 0.1852 - val_acc: 0.9442 - val_dice_axon: 0.7597 - val_dice_myelin: 0.7029 - val_dice_coef: 0.9342\n",
      "Epoch 42/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0212 - acc: 0.9921 - dice_axon: 0.8605 - dice_myelin: 0.7811 - dice_coef: 0.9884 - val_loss: 0.2069 - val_acc: 0.9433 - val_dice_axon: 0.7626 - val_dice_myelin: 0.6946 - val_dice_coef: 0.9343\n",
      "Epoch 43/1000\n",
      "150/150 [==============================] - 92s 617ms/step - loss: 0.0212 - acc: 0.9922 - dice_axon: 0.8635 - dice_myelin: 0.7790 - dice_coef: 0.9885 - val_loss: 0.1425 - val_acc: 0.9555 - val_dice_axon: 0.8021 - val_dice_myelin: 0.7487 - val_dice_coef: 0.9479\n",
      "Epoch 44/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0222 - acc: 0.9922 - dice_axon: 0.8626 - dice_myelin: 0.7802 - dice_coef: 0.9885 - val_loss: 0.2129 - val_acc: 0.9439 - val_dice_axon: 0.7620 - val_dice_myelin: 0.7050 - val_dice_coef: 0.9351\n",
      "Epoch 45/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0207 - acc: 0.9920 - dice_axon: 0.8586 - dice_myelin: 0.7774 - dice_coef: 0.9882 - val_loss: 0.1659 - val_acc: 0.9493 - val_dice_axon: 0.7640 - val_dice_myelin: 0.7137 - val_dice_coef: 0.9393\n",
      "Epoch 46/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0260 - acc: 0.9915 - dice_axon: 0.8559 - dice_myelin: 0.7671 - dice_coef: 0.9876 - val_loss: 0.1732 - val_acc: 0.9494 - val_dice_axon: 0.7787 - val_dice_myelin: 0.7247 - val_dice_coef: 0.9395\n",
      "Epoch 47/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0217 - acc: 0.9920 - dice_axon: 0.8585 - dice_myelin: 0.7774 - dice_coef: 0.9881 - val_loss: 0.1500 - val_acc: 0.9528 - val_dice_axon: 0.8009 - val_dice_myelin: 0.7358 - val_dice_coef: 0.9430\n",
      "Epoch 48/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0196 - acc: 0.9928 - dice_axon: 0.8657 - dice_myelin: 0.7903 - dice_coef: 0.9893 - val_loss: 0.1605 - val_acc: 0.9524 - val_dice_axon: 0.7976 - val_dice_myelin: 0.7528 - val_dice_coef: 0.9455\n",
      "Epoch 49/1000\n",
      "150/150 [==============================] - 95s 631ms/step - loss: 0.0190 - acc: 0.9930 - dice_axon: 0.8739 - dice_myelin: 0.7973 - dice_coef: 0.9897 - val_loss: 0.1858 - val_acc: 0.9469 - val_dice_axon: 0.7880 - val_dice_myelin: 0.7044 - val_dice_coef: 0.9395\n",
      "Epoch 50/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0206 - acc: 0.9929 - dice_axon: 0.8728 - dice_myelin: 0.7942 - dice_coef: 0.9895 - val_loss: 0.1488 - val_acc: 0.9553 - val_dice_axon: 0.8137 - val_dice_myelin: 0.7694 - val_dice_coef: 0.9491\n",
      "Epoch 51/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0200 - acc: 0.9929 - dice_axon: 0.8701 - dice_myelin: 0.7913 - dice_coef: 0.9895 - val_loss: 0.1547 - val_acc: 0.9531 - val_dice_axon: 0.8085 - val_dice_myelin: 0.7533 - val_dice_coef: 0.9467\n",
      "Epoch 52/1000\n",
      "150/150 [==============================] - 94s 627ms/step - loss: 0.0196 - acc: 0.9932 - dice_axon: 0.8741 - dice_myelin: 0.8060 - dice_coef: 0.9898 - val_loss: 0.1578 - val_acc: 0.9544 - val_dice_axon: 0.7998 - val_dice_myelin: 0.7587 - val_dice_coef: 0.9464\n",
      "Epoch 53/1000\n",
      "150/150 [==============================] - 91s 610ms/step - loss: 0.0196 - acc: 0.9925 - dice_axon: 0.8726 - dice_myelin: 0.7949 - dice_coef: 0.9891 - val_loss: 0.1373 - val_acc: 0.9536 - val_dice_axon: 0.8031 - val_dice_myelin: 0.7508 - val_dice_coef: 0.9454\n",
      "Epoch 54/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0491 - acc: 0.9840 - dice_axon: 0.7253 - dice_myelin: 0.6189 - dice_coef: 0.9770 - val_loss: 1.5983 - val_acc: 0.7524 - val_dice_axon: 0.1194 - val_dice_myelin: 0.1393 - val_dice_coef: 0.7542\n",
      "Epoch 55/1000\n",
      "150/150 [==============================] - 95s 632ms/step - loss: 0.0290 - acc: 0.9893 - dice_axon: 0.8070 - dice_myelin: 0.7082 - dice_coef: 0.9843 - val_loss: 0.1637 - val_acc: 0.9486 - val_dice_axon: 0.7754 - val_dice_myelin: 0.7106 - val_dice_coef: 0.9400\n",
      "Epoch 56/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0266 - acc: 0.9904 - dice_axon: 0.8244 - dice_myelin: 0.7332 - dice_coef: 0.9858 - val_loss: 0.1339 - val_acc: 0.9561 - val_dice_axon: 0.7980 - val_dice_myelin: 0.7539 - val_dice_coef: 0.9457\n",
      "Epoch 57/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0254 - acc: 0.9909 - dice_axon: 0.8401 - dice_myelin: 0.7518 - dice_coef: 0.9866 - val_loss: 0.1355 - val_acc: 0.9560 - val_dice_axon: 0.7992 - val_dice_myelin: 0.7528 - val_dice_coef: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "150/150 [==============================] - 88s 586ms/step - loss: 0.0194 - acc: 0.9923 - dice_axon: 0.8559 - dice_myelin: 0.7772 - dice_coef: 0.9887 - val_loss: 0.2782 - val_acc: 0.9390 - val_dice_axon: 0.6845 - val_dice_myelin: 0.7103 - val_dice_coef: 0.9319\n",
      "Epoch 59/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0205 - acc: 0.9923 - dice_axon: 0.8595 - dice_myelin: 0.7806 - dice_coef: 0.9887 - val_loss: 0.1675 - val_acc: 0.9478 - val_dice_axon: 0.7700 - val_dice_myelin: 0.7219 - val_dice_coef: 0.9383\n",
      "Epoch 60/1000\n",
      "150/150 [==============================] - 94s 623ms/step - loss: 0.0242 - acc: 0.9919 - dice_axon: 0.8560 - dice_myelin: 0.7793 - dice_coef: 0.9882 - val_loss: 0.1594 - val_acc: 0.9524 - val_dice_axon: 0.8116 - val_dice_myelin: 0.7480 - val_dice_coef: 0.9464\n",
      "Epoch 61/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0233 - acc: 0.9921 - dice_axon: 0.8603 - dice_myelin: 0.7809 - dice_coef: 0.9882 - val_loss: 0.1667 - val_acc: 0.9533 - val_dice_axon: 0.8010 - val_dice_myelin: 0.7584 - val_dice_coef: 0.9474\n",
      "Epoch 62/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0189 - acc: 0.9928 - dice_axon: 0.8687 - dice_myelin: 0.7947 - dice_coef: 0.9894 - val_loss: 0.1481 - val_acc: 0.9562 - val_dice_axon: 0.8050 - val_dice_myelin: 0.7727 - val_dice_coef: 0.9484\n",
      "Epoch 63/1000\n",
      "150/150 [==============================] - 93s 617ms/step - loss: 0.0193 - acc: 0.9930 - dice_axon: 0.8685 - dice_myelin: 0.7937 - dice_coef: 0.9896 - val_loss: 0.1739 - val_acc: 0.9496 - val_dice_axon: 0.7846 - val_dice_myelin: 0.7402 - val_dice_coef: 0.9439\n",
      "Epoch 64/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0210 - acc: 0.9928 - dice_axon: 0.8700 - dice_myelin: 0.7972 - dice_coef: 0.9893 - val_loss: 0.1640 - val_acc: 0.9531 - val_dice_axon: 0.7960 - val_dice_myelin: 0.7537 - val_dice_coef: 0.9454\n",
      "Epoch 65/1000\n",
      "150/150 [==============================] - 90s 601ms/step - loss: 0.0169 - acc: 0.9936 - dice_axon: 0.8853 - dice_myelin: 0.8170 - dice_coef: 0.9905 - val_loss: 0.2038 - val_acc: 0.9466 - val_dice_axon: 0.7835 - val_dice_myelin: 0.7133 - val_dice_coef: 0.9390\n",
      "Epoch 66/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0182 - acc: 0.9934 - dice_axon: 0.8812 - dice_myelin: 0.8089 - dice_coef: 0.9903 - val_loss: 0.1807 - val_acc: 0.9478 - val_dice_axon: 0.7876 - val_dice_myelin: 0.7176 - val_dice_coef: 0.9415\n",
      "Epoch 67/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0187 - acc: 0.9934 - dice_axon: 0.8838 - dice_myelin: 0.8148 - dice_coef: 0.9902 - val_loss: 0.1776 - val_acc: 0.9497 - val_dice_axon: 0.7949 - val_dice_myelin: 0.7238 - val_dice_coef: 0.9444\n",
      "Epoch 68/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0158 - acc: 0.9940 - dice_axon: 0.8885 - dice_myelin: 0.8216 - dice_coef: 0.9911 - val_loss: 0.1821 - val_acc: 0.9497 - val_dice_axon: 0.7904 - val_dice_myelin: 0.7380 - val_dice_coef: 0.9430\n",
      "Epoch 69/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0171 - acc: 0.9938 - dice_axon: 0.8890 - dice_myelin: 0.8224 - dice_coef: 0.9909 - val_loss: 0.1720 - val_acc: 0.9528 - val_dice_axon: 0.8161 - val_dice_myelin: 0.7608 - val_dice_coef: 0.9478\n",
      "Epoch 70/1000\n",
      "150/150 [==============================] - 91s 604ms/step - loss: 0.0194 - acc: 0.9927 - dice_axon: 0.8739 - dice_myelin: 0.8010 - dice_coef: 0.9894 - val_loss: 0.1759 - val_acc: 0.9496 - val_dice_axon: 0.7847 - val_dice_myelin: 0.7311 - val_dice_coef: 0.9420\n",
      "Epoch 71/1000\n",
      "150/150 [==============================] - 91s 607ms/step - loss: 0.0174 - acc: 0.9935 - dice_axon: 0.8842 - dice_myelin: 0.8141 - dice_coef: 0.9904 - val_loss: 0.1755 - val_acc: 0.9515 - val_dice_axon: 0.7984 - val_dice_myelin: 0.7440 - val_dice_coef: 0.9464\n",
      "Epoch 72/1000\n",
      "150/150 [==============================] - 92s 611ms/step - loss: 0.0170 - acc: 0.9939 - dice_axon: 0.8897 - dice_myelin: 0.8196 - dice_coef: 0.9910 - val_loss: 0.1730 - val_acc: 0.9528 - val_dice_axon: 0.8075 - val_dice_myelin: 0.7585 - val_dice_coef: 0.9479\n",
      "Epoch 73/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0169 - acc: 0.9939 - dice_axon: 0.8891 - dice_myelin: 0.8230 - dice_coef: 0.9909 - val_loss: 0.1810 - val_acc: 0.9495 - val_dice_axon: 0.7936 - val_dice_myelin: 0.7393 - val_dice_coef: 0.9444\n",
      "Epoch 74/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0194 - acc: 0.9936 - dice_axon: 0.8882 - dice_myelin: 0.8236 - dice_coef: 0.9904 - val_loss: 0.2065 - val_acc: 0.9461 - val_dice_axon: 0.7784 - val_dice_myelin: 0.7204 - val_dice_coef: 0.9416\n",
      "Epoch 75/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0171 - acc: 0.9939 - dice_axon: 0.8900 - dice_myelin: 0.8207 - dice_coef: 0.9909 - val_loss: 0.1624 - val_acc: 0.9530 - val_dice_axon: 0.7913 - val_dice_myelin: 0.7636 - val_dice_coef: 0.9460\n",
      "Epoch 76/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0194 - acc: 0.9935 - dice_axon: 0.8862 - dice_myelin: 0.8176 - dice_coef: 0.9902 - val_loss: 0.2083 - val_acc: 0.9450 - val_dice_axon: 0.7708 - val_dice_myelin: 0.7239 - val_dice_coef: 0.9376\n",
      "Epoch 77/1000\n",
      "150/150 [==============================] - 94s 625ms/step - loss: 0.0164 - acc: 0.9942 - dice_axon: 0.8929 - dice_myelin: 0.8295 - dice_coef: 0.9913 - val_loss: 0.2006 - val_acc: 0.9468 - val_dice_axon: 0.7785 - val_dice_myelin: 0.7344 - val_dice_coef: 0.9404\n",
      "Epoch 78/1000\n",
      "150/150 [==============================] - 92s 614ms/step - loss: 0.0201 - acc: 0.9936 - dice_axon: 0.8916 - dice_myelin: 0.8238 - dice_coef: 0.9905 - val_loss: 0.1776 - val_acc: 0.9506 - val_dice_axon: 0.7922 - val_dice_myelin: 0.7565 - val_dice_coef: 0.9443\n",
      "Epoch 79/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0174 - acc: 0.9942 - dice_axon: 0.8930 - dice_myelin: 0.8336 - dice_coef: 0.9913 - val_loss: 0.1883 - val_acc: 0.9504 - val_dice_axon: 0.7991 - val_dice_myelin: 0.7449 - val_dice_coef: 0.9464\n",
      "Epoch 80/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0181 - acc: 0.9939 - dice_axon: 0.8923 - dice_myelin: 0.8250 - dice_coef: 0.9909 - val_loss: 0.1603 - val_acc: 0.9520 - val_dice_axon: 0.8002 - val_dice_myelin: 0.7537 - val_dice_coef: 0.9463\n",
      "Epoch 81/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0189 - acc: 0.9939 - dice_axon: 0.8960 - dice_myelin: 0.8308 - dice_coef: 0.9909 - val_loss: 0.1974 - val_acc: 0.9479 - val_dice_axon: 0.7867 - val_dice_myelin: 0.7466 - val_dice_coef: 0.9421\n",
      "Epoch 82/1000\n",
      "150/150 [==============================] - 90s 603ms/step - loss: 0.0171 - acc: 0.9937 - dice_axon: 0.8866 - dice_myelin: 0.8195 - dice_coef: 0.9906 - val_loss: 0.1743 - val_acc: 0.9497 - val_dice_axon: 0.7803 - val_dice_myelin: 0.7341 - val_dice_coef: 0.9421\n",
      "Epoch 83/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0221 - acc: 0.9930 - dice_axon: 0.8798 - dice_myelin: 0.8109 - dice_coef: 0.9895 - val_loss: 0.1924 - val_acc: 0.9470 - val_dice_axon: 0.7914 - val_dice_myelin: 0.7353 - val_dice_coef: 0.9422\n",
      "Epoch 84/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0148 - acc: 0.9946 - dice_axon: 0.8973 - dice_myelin: 0.8395 - dice_coef: 0.9918 - val_loss: 0.1738 - val_acc: 0.9523 - val_dice_axon: 0.8096 - val_dice_myelin: 0.7534 - val_dice_coef: 0.9483\n",
      "Epoch 85/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0182 - acc: 0.9940 - dice_axon: 0.8951 - dice_myelin: 0.8370 - dice_coef: 0.9911 - val_loss: 0.1871 - val_acc: 0.9498 - val_dice_axon: 0.7846 - val_dice_myelin: 0.7385 - val_dice_coef: 0.9442\n",
      "Epoch 86/1000\n",
      "150/150 [==============================] - 90s 603ms/step - loss: 0.0148 - acc: 0.9946 - dice_axon: 0.9026 - dice_myelin: 0.8458 - dice_coef: 0.9919 - val_loss: 0.1749 - val_acc: 0.9523 - val_dice_axon: 0.7991 - val_dice_myelin: 0.7605 - val_dice_coef: 0.9471\n",
      "Epoch 87/1000\n",
      "150/150 [==============================] - 91s 604ms/step - loss: 0.0174 - acc: 0.9939 - dice_axon: 0.8933 - dice_myelin: 0.8277 - dice_coef: 0.9910 - val_loss: 0.1717 - val_acc: 0.9521 - val_dice_axon: 0.8027 - val_dice_myelin: 0.7545 - val_dice_coef: 0.9470\n"
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 60/100\n",
      "4/4 [==============================] - 3s 833ms/step - loss: 0.0668 - acc: 0.9776 - dice_axon: 0.5014 - dice_myelin: 0.5205 - dice_coef: 0.9635 - val_loss: 0.2296 - val_acc: 0.9179 - val_dice_axon: 0.5433 - val_dice_myelin: 0.5967 - val_dice_coef: 0.8908\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0671 - acc: 0.9744 - dice_axon: 0.5212 - dice_myelin: 0.4464 - dice_coef: 0.9659 - val_loss: 0.2695 - val_acc: 0.8856 - val_dice_axon: 0.5376 - val_dice_myelin: 0.4042 - val_dice_coef: 0.8779\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 4s 889ms/step - loss: 0.0953 - acc: 0.9625 - dice_axon: 0.5090 - dice_myelin: 0.4541 - dice_coef: 0.9556 - val_loss: 0.2238 - val_acc: 0.9145 - val_dice_axon: 0.5831 - val_dice_myelin: 0.5411 - val_dice_coef: 0.8923\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 4s 887ms/step - loss: 0.0746 - acc: 0.9724 - dice_axon: 0.4969 - dice_myelin: 0.4698 - dice_coef: 0.9599 - val_loss: 0.2063 - val_acc: 0.9244 - val_dice_axon: 0.5743 - val_dice_myelin: 0.5864 - val_dice_coef: 0.8975\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0621 - acc: 0.9780 - dice_axon: 0.5131 - dice_myelin: 0.4583 - dice_coef: 0.9632 - val_loss: 0.3771 - val_acc: 0.8692 - val_dice_axon: 0.4275 - val_dice_myelin: 0.3390 - val_dice_coef: 0.8683\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 3s 837ms/step - loss: 0.0790 - acc: 0.9700 - dice_axon: 0.4925 - dice_myelin: 0.4378 - dice_coef: 0.9621 - val_loss: 0.3541 - val_acc: 0.8747 - val_dice_axon: 0.3796 - val_dice_myelin: 0.4123 - val_dice_coef: 0.8680\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0633 - acc: 0.9754 - dice_axon: 0.5068 - dice_myelin: 0.4678 - dice_coef: 0.9644 - val_loss: 0.4597 - val_acc: 0.8526 - val_dice_axon: 0.1799 - val_dice_myelin: 0.2907 - val_dice_coef: 0.8541\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 3s 857ms/step - loss: 0.0729 - acc: 0.9712 - dice_axon: 0.5216 - dice_myelin: 0.5286 - dice_coef: 0.9597 - val_loss: 0.3309 - val_acc: 0.8864 - val_dice_axon: 0.4393 - val_dice_myelin: 0.4016 - val_dice_coef: 0.8775\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 0.0550 - acc: 0.9815 - dice_axon: 0.5349 - dice_myelin: 0.4996 - dice_coef: 0.9719 - val_loss: 0.2297 - val_acc: 0.9177 - val_dice_axon: 0.6099 - val_dice_myelin: 0.5658 - val_dice_coef: 0.9009\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 4s 884ms/step - loss: 0.0831 - acc: 0.9696 - dice_axon: 0.5852 - dice_myelin: 0.4640 - dice_coef: 0.9617 - val_loss: 0.2931 - val_acc: 0.8885 - val_dice_axon: 0.5020 - val_dice_myelin: 0.4109 - val_dice_coef: 0.8802\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.0619 - acc: 0.9766 - dice_axon: 0.5556 - dice_myelin: 0.4820 - dice_coef: 0.9644 - val_loss: 0.3506 - val_acc: 0.8694 - val_dice_axon: 0.3838 - val_dice_myelin: 0.3498 - val_dice_coef: 0.8675\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0654 - acc: 0.9746 - dice_axon: 0.5315 - dice_myelin: 0.4597 - dice_coef: 0.9627 - val_loss: 0.4538 - val_acc: 0.8537 - val_dice_axon: 0.2483 - val_dice_myelin: 0.2757 - val_dice_coef: 0.8572\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 3s 847ms/step - loss: 0.0555 - acc: 0.9802 - dice_axon: 0.5692 - dice_myelin: 0.4973 - dice_coef: 0.9676 - val_loss: 0.3182 - val_acc: 0.8855 - val_dice_axon: 0.4736 - val_dice_myelin: 0.3988 - val_dice_coef: 0.8786\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 4s 904ms/step - loss: 0.0990 - acc: 0.9644 - dice_axon: 0.5696 - dice_myelin: 0.5245 - dice_coef: 0.9541 - val_loss: 0.1985 - val_acc: 0.9252 - val_dice_axon: 0.5807 - val_dice_myelin: 0.5733 - val_dice_coef: 0.8960\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 3s 851ms/step - loss: 0.0722 - acc: 0.9738 - dice_axon: 0.4846 - dice_myelin: 0.4410 - dice_coef: 0.9566 - val_loss: 0.2436 - val_acc: 0.9033 - val_dice_axon: 0.6121 - val_dice_myelin: 0.4699 - val_dice_coef: 0.8942\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 3s 840ms/step - loss: 0.0813 - acc: 0.9701 - dice_axon: 0.5812 - dice_myelin: 0.4565 - dice_coef: 0.9615 - val_loss: 0.3662 - val_acc: 0.8755 - val_dice_axon: 0.4993 - val_dice_myelin: 0.3088 - val_dice_coef: 0.8739\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0742 - acc: 0.9727 - dice_axon: 0.4945 - dice_myelin: 0.4200 - dice_coef: 0.9619 - val_loss: 0.4465 - val_acc: 0.8570 - val_dice_axon: 0.2812 - val_dice_myelin: 0.2964 - val_dice_coef: 0.8582\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.0641 - acc: 0.9767 - dice_axon: 0.5334 - dice_myelin: 0.5257 - dice_coef: 0.9633 - val_loss: 0.2848 - val_acc: 0.8929 - val_dice_axon: 0.4418 - val_dice_myelin: 0.4780 - val_dice_coef: 0.8808\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 4s 883ms/step - loss: 0.0772 - acc: 0.9711 - dice_axon: 0.5216 - dice_myelin: 0.5044 - dice_coef: 0.9581 - val_loss: 0.3851 - val_acc: 0.8651 - val_dice_axon: 0.4050 - val_dice_myelin: 0.3137 - val_dice_coef: 0.8666\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 3s 875ms/step - loss: 0.0501 - acc: 0.9821 - dice_axon: 0.5309 - dice_myelin: 0.4498 - dice_coef: 0.9705 - val_loss: 0.2917 - val_acc: 0.8816 - val_dice_axon: 0.5692 - val_dice_myelin: 0.3649 - val_dice_coef: 0.8801\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 4s 878ms/step - loss: 0.0795 - acc: 0.9661 - dice_axon: 0.5652 - dice_myelin: 0.4120 - dice_coef: 0.9599 - val_loss: 0.4014 - val_acc: 0.8670 - val_dice_axon: 0.4343 - val_dice_myelin: 0.3028 - val_dice_coef: 0.8670\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0605 - acc: 0.9775 - dice_axon: 0.5953 - dice_myelin: 0.5506 - dice_coef: 0.9658 - val_loss: 0.2555 - val_acc: 0.9061 - val_dice_axon: 0.5178 - val_dice_myelin: 0.5050 - val_dice_coef: 0.8911\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.0657 - acc: 0.9769 - dice_axon: 0.5500 - dice_myelin: 0.4794 - dice_coef: 0.9672 - val_loss: 0.2271 - val_acc: 0.9151 - val_dice_axon: 0.5796 - val_dice_myelin: 0.5594 - val_dice_coef: 0.8987\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 0.0569 - acc: 0.9791 - dice_axon: 0.6201 - dice_myelin: 0.5553 - dice_coef: 0.9694 - val_loss: 0.2224 - val_acc: 0.9119 - val_dice_axon: 0.5815 - val_dice_myelin: 0.5153 - val_dice_coef: 0.8944\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 3s 871ms/step - loss: 0.0689 - acc: 0.9738 - dice_axon: 0.5677 - dice_myelin: 0.5024 - dice_coef: 0.9624 - val_loss: 0.4021 - val_acc: 0.8658 - val_dice_axon: 0.3434 - val_dice_myelin: 0.3130 - val_dice_coef: 0.8660\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 3s 796ms/step - loss: 0.0596 - acc: 0.9780 - dice_axon: 0.5794 - dice_myelin: 0.5052 - dice_coef: 0.9673 - val_loss: 0.3876 - val_acc: 0.8716 - val_dice_axon: 0.3615 - val_dice_myelin: 0.3560 - val_dice_coef: 0.8696\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0627 - acc: 0.9761 - dice_axon: 0.5988 - dice_myelin: 0.5455 - dice_coef: 0.9660 - val_loss: 0.2551 - val_acc: 0.9023 - val_dice_axon: 0.4773 - val_dice_myelin: 0.5052 - val_dice_coef: 0.8862\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 3s 845ms/step - loss: 0.0497 - acc: 0.9825 - dice_axon: 0.5301 - dice_myelin: 0.4776 - dice_coef: 0.9709 - val_loss: 0.3183 - val_acc: 0.8753 - val_dice_axon: 0.3875 - val_dice_myelin: 0.4134 - val_dice_coef: 0.8734\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 4s 884ms/step - loss: 0.0719 - acc: 0.9721 - dice_axon: 0.5770 - dice_myelin: 0.5607 - dice_coef: 0.9604 - val_loss: 0.2929 - val_acc: 0.8992 - val_dice_axon: 0.4979 - val_dice_myelin: 0.4767 - val_dice_coef: 0.8844\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 4s 880ms/step - loss: 0.0519 - acc: 0.9804 - dice_axon: 0.5851 - dice_myelin: 0.5535 - dice_coef: 0.9701 - val_loss: 0.2478 - val_acc: 0.9010 - val_dice_axon: 0.5660 - val_dice_myelin: 0.4762 - val_dice_coef: 0.8912\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 3s 837ms/step - loss: 0.0684 - acc: 0.9735 - dice_axon: 0.5883 - dice_myelin: 0.4752 - dice_coef: 0.9660 - val_loss: 0.4134 - val_acc: 0.8735 - val_dice_axon: 0.3790 - val_dice_myelin: 0.3864 - val_dice_coef: 0.8698\n"
=======
      "Epoch 88/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0149 - acc: 0.9945 - dice_axon: 0.9014 - dice_myelin: 0.8436 - dice_coef: 0.9919 - val_loss: 0.1923 - val_acc: 0.9486 - val_dice_axon: 0.7902 - val_dice_myelin: 0.7332 - val_dice_coef: 0.9434\n",
      "Epoch 89/1000\n",
      "150/150 [==============================] - 92s 611ms/step - loss: 0.0137 - acc: 0.9949 - dice_axon: 0.9057 - dice_myelin: 0.8474 - dice_coef: 0.9924 - val_loss: 0.1804 - val_acc: 0.9514 - val_dice_axon: 0.8057 - val_dice_myelin: 0.7553 - val_dice_coef: 0.9470\n",
      "Epoch 90/1000\n",
      "150/150 [==============================] - 91s 605ms/step - loss: 0.0166 - acc: 0.9944 - dice_axon: 0.9044 - dice_myelin: 0.8463 - dice_coef: 0.9917 - val_loss: 0.1855 - val_acc: 0.9499 - val_dice_axon: 0.8003 - val_dice_myelin: 0.7456 - val_dice_coef: 0.9457\n",
      "Epoch 91/1000\n",
      "150/150 [==============================] - 84s 563ms/step - loss: 0.0140 - acc: 0.9950 - dice_axon: 0.9101 - dice_myelin: 0.8522 - dice_coef: 0.9926 - val_loss: 0.2225 - val_acc: 0.9433 - val_dice_axon: 0.7766 - val_dice_myelin: 0.7167 - val_dice_coef: 0.9378\n",
      "Epoch 92/1000\n",
      "150/150 [==============================] - 87s 580ms/step - loss: 0.0118 - acc: 0.9954 - dice_axon: 0.9179 - dice_myelin: 0.8644 - dice_coef: 0.9932 - val_loss: 0.1903 - val_acc: 0.9533 - val_dice_axon: 0.8123 - val_dice_myelin: 0.7681 - val_dice_coef: 0.9502\n",
      "Epoch 93/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0162 - acc: 0.9945 - dice_axon: 0.9081 - dice_myelin: 0.8548 - dice_coef: 0.9919 - val_loss: 0.1702 - val_acc: 0.9501 - val_dice_axon: 0.8001 - val_dice_myelin: 0.7441 - val_dice_coef: 0.9440\n",
      "Epoch 94/1000\n",
      "150/150 [==============================] - 85s 566ms/step - loss: 0.0140 - acc: 0.9949 - dice_axon: 0.9069 - dice_myelin: 0.8520 - dice_coef: 0.9924 - val_loss: 0.1867 - val_acc: 0.9501 - val_dice_axon: 0.8136 - val_dice_myelin: 0.7517 - val_dice_coef: 0.9468\n",
      "Epoch 95/1000\n",
      "150/150 [==============================] - 86s 572ms/step - loss: 0.0129 - acc: 0.9951 - dice_axon: 0.9128 - dice_myelin: 0.8585 - dice_coef: 0.9927 - val_loss: 0.1755 - val_acc: 0.9517 - val_dice_axon: 0.8035 - val_dice_myelin: 0.7461 - val_dice_coef: 0.9476\n",
      "Epoch 96/1000\n",
      "150/150 [==============================] - 88s 590ms/step - loss: 0.0130 - acc: 0.9952 - dice_axon: 0.9151 - dice_myelin: 0.8628 - dice_coef: 0.9930 - val_loss: 0.1811 - val_acc: 0.9528 - val_dice_axon: 0.8136 - val_dice_myelin: 0.7681 - val_dice_coef: 0.9495\n",
      "Epoch 97/1000\n",
      "150/150 [==============================] - 86s 576ms/step - loss: 0.0119 - acc: 0.9953 - dice_axon: 0.9178 - dice_myelin: 0.8676 - dice_coef: 0.9931 - val_loss: 0.1764 - val_acc: 0.9544 - val_dice_axon: 0.8179 - val_dice_myelin: 0.7800 - val_dice_coef: 0.9508\n",
      "Epoch 98/1000\n",
      "150/150 [==============================] - 87s 578ms/step - loss: 0.0128 - acc: 0.9952 - dice_axon: 0.9173 - dice_myelin: 0.8633 - dice_coef: 0.9930 - val_loss: 0.2019 - val_acc: 0.9489 - val_dice_axon: 0.7936 - val_dice_myelin: 0.7497 - val_dice_coef: 0.9447\n",
      "Epoch 99/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0148 - acc: 0.9949 - dice_axon: 0.9082 - dice_myelin: 0.8534 - dice_coef: 0.9925 - val_loss: 0.1885 - val_acc: 0.9516 - val_dice_axon: 0.8167 - val_dice_myelin: 0.7653 - val_dice_coef: 0.9485\n",
      "Epoch 100/1000\n",
      "150/150 [==============================] - 88s 584ms/step - loss: 0.0134 - acc: 0.9951 - dice_axon: 0.9143 - dice_myelin: 0.8613 - dice_coef: 0.9927 - val_loss: 0.2183 - val_acc: 0.9467 - val_dice_axon: 0.7720 - val_dice_myelin: 0.7246 - val_dice_coef: 0.9409\n",
      "Epoch 101/1000\n",
      "150/150 [==============================] - 87s 581ms/step - loss: 0.0164 - acc: 0.9945 - dice_axon: 0.9076 - dice_myelin: 0.8490 - dice_coef: 0.9920 - val_loss: 0.1637 - val_acc: 0.9555 - val_dice_axon: 0.8236 - val_dice_myelin: 0.7795 - val_dice_coef: 0.9515\n",
      "Epoch 102/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0124 - acc: 0.9952 - dice_axon: 0.9137 - dice_myelin: 0.8607 - dice_coef: 0.9928 - val_loss: 0.1876 - val_acc: 0.9524 - val_dice_axon: 0.8113 - val_dice_myelin: 0.7719 - val_dice_coef: 0.9493\n",
      "Epoch 103/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0162 - acc: 0.9946 - dice_axon: 0.9017 - dice_myelin: 0.8433 - dice_coef: 0.9921 - val_loss: 0.1740 - val_acc: 0.9541 - val_dice_axon: 0.8092 - val_dice_myelin: 0.7702 - val_dice_coef: 0.9493\n",
      "Epoch 104/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0130 - acc: 0.9954 - dice_axon: 0.9125 - dice_myelin: 0.8626 - dice_coef: 0.9931 - val_loss: 0.1761 - val_acc: 0.9537 - val_dice_axon: 0.8168 - val_dice_myelin: 0.7715 - val_dice_coef: 0.9500\n",
      "Epoch 105/1000\n",
      "115/150 [======================>.......] - ETA: 20s - loss: 0.0130 - acc: 0.9953 - dice_axon: 0.9132 - dice_myelin: 0.8606 - dice_coef: 0.9931"
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.0596 - acc: 0.9774 - dice_axon: 0.5907 - dice_myelin: 0.5468 - dice_coef: 0.9667 - val_loss: 0.2030 - val_acc: 0.9246 - val_dice_axon: 0.6048 - val_dice_myelin: 0.6041 - val_dice_coef: 0.9028\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 3s 872ms/step - loss: 0.0719 - acc: 0.9720 - dice_axon: 0.5816 - dice_myelin: 0.5271 - dice_coef: 0.9614 - val_loss: 0.2640 - val_acc: 0.8982 - val_dice_axon: 0.5680 - val_dice_myelin: 0.4457 - val_dice_coef: 0.8890\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 3s 831ms/step - loss: 0.0410 - acc: 0.9854 - dice_axon: 0.5655 - dice_myelin: 0.4640 - dice_coef: 0.9758 - val_loss: 0.2955 - val_acc: 0.8828 - val_dice_axon: 0.5471 - val_dice_myelin: 0.3811 - val_dice_coef: 0.8814\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 4s 885ms/step - loss: 0.0656 - acc: 0.9745 - dice_axon: 0.5736 - dice_myelin: 0.4658 - dice_coef: 0.9661 - val_loss: 0.2224 - val_acc: 0.9169 - val_dice_axon: 0.5912 - val_dice_myelin: 0.5648 - val_dice_coef: 0.8990\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 3s 855ms/step - loss: 0.0748 - acc: 0.9714 - dice_axon: 0.5900 - dice_myelin: 0.5298 - dice_coef: 0.9605 - val_loss: 0.4864 - val_acc: 0.8631 - val_dice_axon: 0.2912 - val_dice_myelin: 0.2841 - val_dice_coef: 0.8618\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 4s 995ms/step - loss: 0.0575 - acc: 0.9792 - dice_axon: 0.5668 - dice_myelin: 0.4809 - dice_coef: 0.9659 - val_loss: 0.3150 - val_acc: 0.8846 - val_dice_axon: 0.4678 - val_dice_myelin: 0.4201 - val_dice_coef: 0.8787\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 0.0532 - acc: 0.9807 - dice_axon: 0.6124 - dice_myelin: 0.5366 - dice_coef: 0.9679 - val_loss: 0.3580 - val_acc: 0.8887 - val_dice_axon: 0.5138 - val_dice_myelin: 0.4094 - val_dice_coef: 0.8815\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 3s 867ms/step - loss: 0.0530 - acc: 0.9807 - dice_axon: 0.5704 - dice_myelin: 0.5129 - dice_coef: 0.9717 - val_loss: 0.6050 - val_acc: 0.8534 - val_dice_axon: 0.2481 - val_dice_myelin: 0.2211 - val_dice_coef: 0.8532\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 3s 825ms/step - loss: 0.0467 - acc: 0.9839 - dice_axon: 0.6174 - dice_myelin: 0.5356 - dice_coef: 0.9748 - val_loss: 0.3579 - val_acc: 0.8812 - val_dice_axon: 0.5308 - val_dice_myelin: 0.3992 - val_dice_coef: 0.8797\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.0850 - acc: 0.9682 - dice_axon: 0.5470 - dice_myelin: 0.5048 - dice_coef: 0.9595 - val_loss: 0.3653 - val_acc: 0.8833 - val_dice_axon: 0.3766 - val_dice_myelin: 0.3977 - val_dice_coef: 0.8742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83f04dd860>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, validation_data = valid_gen, steps_per_epoch=train_steps, validation_steps = 2,\n",
<<<<<<< HEAD
    "                    epochs= 100,  callbacks = [tensorboard, checkpoint_loss, checkpoint_acc])\n",
=======
    "                    epochs= 1000,  callbacks = [tensorboard])\n",
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save model\n",
    "model.save(\"models/\"+Name+'/model.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# To load the model\n",
    "custom_objects={'dice_axon': dice_axon,'dice_myelin':dice_myelin,'dice_coef':dice_coef}\n",
    "model = load_model(\"models/\"+Name+\"/model.hdf5\", custom_objects = custom_objects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = K.get_session()\n",
    "save_path = saver.save(sess, \"models/\"+Name+\"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# AxonDeepSeg imports\n",
    "try:\n",
    "    from AxonDeepSeg.ads_utils import download_data\n",
    "except ModuleNotFoundError:\n",
    "    # Change cwd to project main folder \n",
    "    os.chdir(\"..\")\n",
    "    try :\n",
    "        from AxonDeepSeg.ads_utils import download_data\n",
    "    except:\n",
    "        raise\n",
    "except:\n",
    "    raise\n",
    "# If no exceptions were raised import all folders        \n",
    "from AxonDeepSeg.config_tools import validate_config\n",
    "from AxonDeepSeg.train_network import train_model\n",
    "from AxonDeepSeg.apply_model import axon_segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the lines below to use your image\n",
    "path_img = Path(\"./TEM_striatum_2/data/Testing\")\n",
    "file_img = \"image_819.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('models/TEM_sample_dataset-2019-06-11 04:33:07')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_img\n",
    "path_model = Path(\"./models/\"+Name+\"/\")\n",
    "path_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading acquisitions ...\n",
      "Rescaling acquisitions to the target resolution ...\n",
      "Graph construction ...\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-439d56069c47>\", line 7, in <module>\n    prediction = axon_segmentation(path_img, file_img, path_model, training_config, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 259, in axon_segmentation\n    verbosity_level=verbosity_level)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 70, in apply_convnet\n    saver = tf.train.Saver()  # Load previous model\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n\t [[{{node save/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-439d56069c47>\", line 7, in <module>\n    prediction = axon_segmentation(path_img, file_img, path_model, training_config, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 259, in axon_segmentation\n    verbosity_level=verbosity_level)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 70, in apply_convnet\n    saver = tf.train.Saver()  # Load previous model\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-439d56069c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# reset the tensorflow graph for new testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxon_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquired_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampled_resolutions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/axondeepseg/AxonDeepSeg/apply_model.py\u001b[0m in \u001b[0;36maxon_segmentation\u001b[0;34m(path_acquisitions_folders, acquisitions_filenames, path_model_folder, config_dict, ckpt_name, segmentations_filenames, inference_batch_size, overlap_value, resampled_resolutions, acquired_resolution, prediction_proba_activate, write_mode, gpu_per, verbosity_level)\u001b[0m\n\u001b[1;32m    257\u001b[0m                                    \u001b[0moverlap_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverlap_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresampled_resolutions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresampled_resolutions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                                    \u001b[0mprediction_proba_activate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_proba_activate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_per\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                                    verbosity_level=verbosity_level)\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Predictions are shape of image, value = class of pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/axondeepseg/AxonDeepSeg/apply_model.py\u001b[0m in \u001b[0;36mapply_convnet\u001b[0;34m(path_acquisitions, acquisitions_resolutions, path_model_folder, config_dict, ckpt_name, inference_batch_size, overlap_value, resampled_resolutions, prediction_proba_activate, gpu_per, verbosity_level)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmodel_previous_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_model_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_previous_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# STEP 3: Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-439d56069c47>\", line 7, in <module>\n    prediction = axon_segmentation(path_img, file_img, path_model, training_config, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 259, in axon_segmentation\n    verbosity_level=verbosity_level)\n  File \"/home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py\", line 70, in apply_convnet\n    saver = tf.train.Saver()  # Load previous model\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey cconv-d0-c0/convolution/bn/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n\t [[node save/RestoreV2 (defined at /home/vasha_local/axondeepseg/AxonDeepSeg/apply_model.py:70) ]]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 0a8065d877d65560ca33bc5ccf5c70f0b2e873a4
   "source": [
    "# In case you want to test the segmentation with a pre-trained model created using this notebook,\n",
    "# uncomment the line below.\n",
    "path_model = Path(\"./models/\"+Name+\"/\")\n",
    "\n",
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "prediction = axon_segmentation(path_img, file_img, path_model, training_config, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Ground Truth\n",
    "plt.imshow(y[7,:,:,2], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result[7,:,:,2], cmap = \"gray\") # Predicted Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo - Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''# Modify the lines below to use your image\n",
    "path_img = Path(\"./TEM_striatum/data/Testing\")\n",
    "file_img = \"image_819.png\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-29-ab792477a621>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-ab792477a621>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    prediction = axon_segmentation(path_img, file_img, path_model, config_network, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\u001b[0m\n\u001b[0m                                                                                                                                                           \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''# In case you want to test the segmentation with a pre-trained model created using this notebook,\n",
    "# uncomment the line below.\n",
    "path_model = Path(\"./TEM_striatum/model/TEM_3c_512_2018-11-10_21-32-36/\")\n",
    "\n",
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "prediction = axon_segmentation(path_img, file_img, path_model, config_network, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-30-da19f92788a1>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-da19f92788a1>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    plt.show()\u001b[0m\n\u001b[0m              \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''file_img_seg = 'AxonDeepSeg.png'  # axon+myelin segmentation\n",
    "\n",
    "img_seg = imageio.imread(path_img / file_img_seg)\n",
    "img = imageio.imread(path_img / file_img)\n",
    "# Note: The arguments of the two function calls above use the pathlib syntax for path concatenation.\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(13,10))\n",
    "ax1, ax2 = axes[0], axes[1]\n",
    "ax1.set_title('Original image')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Prediction with the trained model')\n",
    "ax2.imshow(img_seg,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
