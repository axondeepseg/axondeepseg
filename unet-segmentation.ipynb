{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET SEGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arxiv Link: <a href=\"https://arxiv.org/abs/1505.04597\">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>UNet is a fully convolutional network(FCN) that does image segmentation. Its goal is to predict each pixel's class.</li>\n",
    " \n",
    "<li>UNet is built upon the FCN and modified in a way that it yields better segmentation in medical imaging.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Architecture\n",
    "\n",
    "<img src=\"images/u-net-architecture.png\"/>\n",
    "\n",
    "<h3>UNet Architecture has 3 parts:</h3>\n",
    "<ol>\n",
    "    <li>The Contracting/Downsampling Path</li>\n",
    "    <li>Bottleneck</li>\n",
    "    <li>The Expanding/Upsampling Path</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Downsampling Path: </h3> \n",
    "<ol>\n",
    "    <li>It consists of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling.</li> \n",
    "    <li>At each downsampling step we double the number of feature channels.</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Upsampling Path: </h3> \n",
    "<ol>\n",
    "     <li> Every  step  in  the  expansive  path  consists  of  an  upsampling  of  the feature map followed by a 2x2 convolution (“up-convolution”), a concatenation with the correspondingly feature  map  from  the  downsampling  path,  and  two  3x3  convolutions,  each  followed by a ReLU.</li>\n",
    "</ol>\n",
    "\n",
    "<h3> Skip Connection: </h3>\n",
    "The skip connection from the downsampling path are concatenated with feature map during upsampling path. These skip connection provide local information to global information while upsampling.\n",
    "\n",
    "<h3> Final Layer: </h3>\n",
    "At the final layer a 1x1 convolution is used to map each feature vector to the desired number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Advantages\n",
    "<h3> Advantages: </h3>\n",
    "<ol>\n",
    "    <li>The UNet combines the location information from the downsampling path to finally obtain a general information combining localisation and context, which is necessary to predict a good segmentation map.</li>\n",
    "    <li>No Dense layer is used, so image sizes can be used.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Dataset\n",
    "Link: <a href=\"https://www.kaggle.com/c/data-science-bowl-2018\">Data Science Bowl 2018</a>\n",
    "Find the nuclei in divergent images to advance medical discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## Seeding \\nseed = 2019\\nrandom.seed = seed\\nnp.random.seed = seed\\ntf.seed = seed'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Imports\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import * \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from data_prep import *\n",
    "\n",
    "#Tensorboard for Visualization\n",
    "from keras.callbacks import TensorBoard \n",
    "import time\n",
    "\n",
    "\"\"\"\n",
    "## Seeding \n",
    "seed = 2019\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "tf.seed = seed\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "K.set_session\n",
    "import tensorflow as tf\n",
    "#K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import json\n",
    "with open('/Users/vasudevsharma/Desktop/axondeepseg-master-2/AxonDeepSeg/models/default_SEM_model_v1/config_network.json') as djson:\n",
    "    training_config = json.load(djson)\n",
    "print(training_config) \"\"\"\n",
    "# Example of network configuration for TEM data (small network trainable on a Titan X GPU card)\n",
    "training_config = {\n",
    "    \n",
    "# General parameters:    \n",
    "  \"n_classes\": 3,  # Number of classes. For this application, the number of classes should be set to **3** (i.e. axon pixel, myelin pixel, or background pixel).\n",
    "  \"thresholds\": [0, 0.2, 0.8],  # Thresholds for the 3-class classification problem. Do not modify.  \n",
    "  \"trainingset_patchsize\": 512,  # Patch size of the training set in pixels (note that the patches have the same size in both dimensions).  \n",
    "  \"trainingset\": \"TEM_3c_512\",  # Name of the training set.\n",
    "  \"batch_size\": 8,  # Batch size, i.e. the number of training patches used in one iteration of the training. Note that a larger batch size will take more memory.\n",
    "\n",
    "# Network architecture parameters:     \n",
    "  \"depth\": 4,  # Depth of the network (i.e. number of blocks of the U-net).\n",
    "  \"convolution_per_layer\": [2, 2, 2, 2],  # Number of convolution layers used at each block.\n",
    "  \"size_of_convolutions_per_layer\": [[5, 5], [3, 3], [3, 3], [3, 3]],  # Kernel size of each convolution layer of the network.\n",
    "  \"features_per_convolution\": [[[1, 16], [16, 16]], [[16, 32], [32, 32]], [[32, 64], [64, 64]], [[64, 128], [128, 128]]],  # Number of features of each convolution layer.\n",
    "  \"downsampling\": \"convolution\",  # Type of downsampling to use in the downsampling layers of the network. Option \"maxpooling\" for standard max pooling layer or option \"convolution\" for learned convolutional downsampling.\n",
    "  \"dropout\": 0.75,  # Dropout to use for the training. Note: In TensorFlow, the keep probability is used instead. For instance, setting this param. to 0.75 means that 75% of the neurons of the network will be kept (i.e. dropout of 25%).\n",
    "     \n",
    "# Learning rate parameters:    \n",
    "  \"learning_rate\": 0.01,  # Learning rate to use in the training.  \n",
    "  \"learning_rate_decay_activate\": True,  # Set to \"True\" to use a decay on the learning rate.  \n",
    "  \"learning_rate_decay_period\": 24000,  # Period of the learning rate decay, expressed in number of images (samples) seen.\n",
    "  \"learning_rate_decay_type\": \"polynomial\",  # Type of decay to use. An exponential decay will be used by default unless this param. is set to \"polynomial\" (to use a polynomial decay).\n",
    "  \"learning_rate_decay_rate\": 0.99,  # Rate of the decay to use for the exponential decay. This only applies when the user does not set the decay type to \"polynomial\".\n",
    "    \n",
    "# Batch normalization parameters:     \n",
    "  \"batch_norm_activate\": True,  # Set to \"True\" to use batch normalization during the training.\n",
    "  \"batch_norm_decay_decay_activate\": True,  # Set to \"True\" to activate an exponential decay for the batch normalization step of the training.  \n",
    "  \"batch_norm_decay_starting_decay\": 0.7,  # The starting decay value for the batch normalization. \n",
    "  \"batch_norm_decay_ending_decay\": 0.9,  # The ending decay value for the batch normalization.\n",
    "  \"batch_norm_decay_decay_period\": 16000,  # Period of the batch normalization decay, expressed in number of images (samples) seen.\n",
    "        \n",
    "# Weighted cost parameters:    \n",
    "  \"weighted_cost-activate\": True,  # Set to \"True\" to use weights based on the class in the cost function for the training.\n",
    "  \"weighted_cost-balanced_activate\": True,  # Set to \"True\" to use weights in the cost function to correct class imbalance. \n",
    "  \"weighted_cost-balanced_weights\": [1.1, 1, 1.3],  # Values of the weights for the class imbalance. Typically, larger weights are assigned to classes with less pixels to add more penalty in the cost function when there is a misclassification. Order of the classes in the weights list: background, myelin, axon.\n",
    "  \"weighted_cost-boundaries_sigma\": 2,  # Set to \"True\" to add weights to the boundaries (e.g. penalize more when misclassification happens in the axon-myelin interface).\n",
    "  \"weighted_cost-boundaries_activate\": False,  # Value to control the distribution of the boundary weights (if activated). \n",
    "    \n",
    "# Data augmentation parameters:\n",
    "  \"da-type\": \"all\",  # Type of data augmentation procedure. Option \"all\" applies all selected data augmentation transformations sequentially, while option \"random\" only applies one of the selected transformations (randomly) to the sample(s). List of available data augmentation transformations: 'random_rotation', 'noise_addition', 'elastic', 'shifting', 'rescaling' and 'flipping'. \n",
    "  \"da-0-shifting-activate\": True, \n",
    "  \"da-1-rescaling-activate\": False,\n",
    "  \"da-2-random_rotation-activate\": False,  \n",
    "  \"da-3-elastic-activate\": True, \n",
    "  \"da-4-flipping-activate\": True, \n",
    "  \"da-5-noise_addition-activate\": False\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Convolutional Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def upconv(x, n_out_chan, scope, \\n              w_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\\n              training_phase=True, activate_bn = True, bn_decay = 0.999):\\n   \\n    \\n    with tf.variable_scope(scope):\\n        if activate_bn == True:\\n            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \\n                                       activation_fn=tf.nn.relu, normalizer_fn=tf.contrib.layers.batch_norm,\\n                                       normalizer_params={'scale':True, 'is_training':training_phase,\\n                                                          'decay':bn_decay, 'scope':'bn'},\\n                                       weights_initializer = w_initializer, scope='convolution'\\n                                      )\\n        else:\\n            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \\n                                       activation_fn=tf.nn.relu, weights_initializer = w_initializer, scope='convolution'\\n                                      )\\n        \\n        tf.add_to_collection('activations',net)\\n        return net\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv_relu(x, filters , kernel_size , strides , activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999, keep_prob=1.0):\n",
    "    if activate_bn == True:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same', activation = activation, kernel_initializer = kernel_initializer)(x)\n",
    "            net = BatchNormalization(axis = 3, momentum = 1 - bn_decay)(net)\n",
    "            \n",
    "    else: \n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, activation = activation, kernel_initializer = kernel_initializer, padding = 'same')(net)\n",
    "            \n",
    "    net =  Dropout(rate = 1 - keep_prob)(net)\n",
    "            \n",
    "    return net \n",
    "\n",
    "   \n",
    "def downconv(x, filters , kernel_size = 5, strides = 2, activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999):\n",
    "    if activate_bn == True:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = 'same',activation = activation, kernel_initializer = kernel_initializer)(x)\n",
    "            net = BatchNormalization(axis = 3, momentum = 1 - bn_decay)(net)\n",
    "\n",
    "    else:\n",
    "\n",
    "            net = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, activation = activation, kernel_initializer = kernel_initializer, padding = 'same')(net)\n",
    "            \n",
    "    return net\n",
    "\n",
    "\"\"\"def upconv(x, n_out_chan, scope, \n",
    "              w_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "              training_phase=True, activate_bn = True, bn_decay = 0.999):\n",
    "   \n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        if activate_bn == True:\n",
    "            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \n",
    "                                       activation_fn=tf.nn.relu, normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "                                       normalizer_params={'scale':True, 'is_training':training_phase,\n",
    "                                                          'decay':bn_decay, 'scope':'bn'},\n",
    "                                       weights_initializer = w_initializer, scope='convolution'\n",
    "                                      )\n",
    "        else:\n",
    "            net = tf.contrib.layers.conv2d(x, num_outputs=n_out_chan, kernel_size=3, stride=1, \n",
    "                                       activation_fn=tf.nn.relu, weights_initializer = w_initializer, scope='convolution'\n",
    "                                      )\n",
    "        \n",
    "        tf.add_to_collection('activations',net)\n",
    "        return net\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------------------ NETWORK STRUCTURE ------------------------ #\n",
    "\n",
    "\n",
    "def uconv_net(training_config,bn_updated_decay = None, verbose = True):\n",
    "    \"\"\"\n",
    "    Create the U-net.\n",
    "    Input :\n",
    "        x : TF object to define, ensemble des patchs des images :graph input\n",
    "        config : dict : described in the header.\n",
    "        image_size : int : The image size\n",
    "\n",
    "    Output :\n",
    "        The U-net.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the variables\n",
    "    image_size = training_config[\"trainingset_patchsize\"]\n",
    "    n_classes = training_config[\"n_classes\"]\n",
    "    depth = training_config[\"depth\"]\n",
    "    dropout = training_config[\"dropout\"]\n",
    "    number_of_convolutions_per_layer = training_config[\"convolution_per_layer\"]\n",
    "    size_of_convolutions_per_layer = training_config[\"size_of_convolutions_per_layer\"]\n",
    "    features_per_convolution = training_config[\"features_per_convolution\"]\n",
    "    downsampling = training_config[\"downsampling\"]\n",
    "    activate_bn = training_config[\"batch_norm_activate\"]\n",
    "    if bn_updated_decay is None:\n",
    "        bn_decay = training_config[\"batch_norm_decay_starting_decay\"]\n",
    "    else:\n",
    "        bn_decay = bn_updated_decay\n",
    "\n",
    "    # Input picture shape is [batch_size, height, width, number_channels_in] (number_channels_in = 1 for the input layer)\n",
    "    \n",
    "    data_temp_size = [image_size]\n",
    "    relu_results = []\n",
    "\n",
    "    ####################################################################\n",
    "    ######################### CONTRACTION PHASE ########################\n",
    "    ####################################################################\n",
    "    \n",
    "\n",
    "\n",
    "   # print(data_temp)\n",
    "\n",
    "    #X = Input((image_size*image_size, 3))\n",
    "    X = Input((image_size, image_size, 3))\n",
    " \n",
    "    net = X\n",
    "    data_temp = X\n",
    "   # print(net.shape)\n",
    "    #print(depth, number_of_convolutions_per_layer)\n",
    "    for i in range(depth):\n",
    "\n",
    "        for conv_number in range(number_of_convolutions_per_layer[i]):\n",
    "            \n",
    "            if verbose:\n",
    "                #print(('Layer: ', i, ' Conv: ', conv_number, 'Features: ', features_per_convolution[i][conv_number]))\n",
    "                #print(('Size:', size_of_convolutions_per_layer[i][conv_number]))\n",
    "                \n",
    "                net = conv_relu(net, filters = features_per_convolution[i][conv_number][1], kernel_size = size_of_convolutions_per_layer[i][conv_number], strides = 1 , activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999, keep_prob=1.0)\n",
    "               \n",
    "        relu_results.append(net) # We keep them for the upconvolutions\n",
    "    \n",
    "\n",
    "        if downsampling == 'convolution':\n",
    "              \n",
    "            net = downconv(net, filters = features_per_convolution[i][conv_number][1], kernel_size = 5, strides = 2, activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999)\n",
    "      \n",
    "        else: \n",
    "\n",
    "            net = MaxPooling2D((2, 2), padding = 'valid', strides = 2,  name ='downmp-d'+str(i))(net)\n",
    "\n",
    "        data_temp_size.append(data_temp_size[-1] // 2)\n",
    "        data_temp = net\n",
    "             \n",
    "\n",
    "\n",
    "    ####################################################################\n",
    "    ########################## EXPANSION PHASE #########################\n",
    "    ####################################################################\n",
    "    \n",
    "    for i in range(depth):        \n",
    "        # Upsampling\n",
    "        net = UpSampling2D(( 2,  2))(net)\n",
    "     \n",
    "\n",
    "        # Convolution\n",
    "        net = conv_relu(net, filters = features_per_convolution[depth - i - 1][-1][1], kernel_size = 2, strides = 1 , activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999, keep_prob=1.0)\n",
    "        \n",
    "        data_temp_size.append(data_temp_size[-1] * 2)\n",
    "\n",
    "        # concatenation (see U-net article)\n",
    "        net = Concatenate(axis = 3)([relu_results[depth-i-1],net])\n",
    "      \n",
    "\n",
    "        # Classic convolutions\n",
    "        for conv_number in range(number_of_convolutions_per_layer[depth - i - 1]):\n",
    "            \n",
    "            net = conv_relu(net, filters = features_per_convolution[depth - i - 1][conv_number][1], kernel_size = size_of_convolutions_per_layer[depth - i - 1][conv_number], strides = 1 , activation = 'relu', kernel_initializer = 'glorot_normal', activate_bn = True, bn_decay = 0.999, keep_prob=1.0)\n",
    "            \n",
    "            \n",
    "        data_temp = net\n",
    "\n",
    "   \n",
    "    net = Conv2D(filters = n_classes, kernel_size = 1, strides = 1, name = 'finalconv', padding = 'same',   activation = \"softmax\")(net)\n",
    "\n",
    "    model = Model(inputs = X, outputs = net)\n",
    "\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n",
    "        \n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "def dice_myelin(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true[..., 1])\n",
    "    y_pred_f = K.flatten(y_pred[..., 1])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "def dice_axon(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true[..., 2])\n",
    "    y_pred_f = K.flatten(y_pred[..., 2])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return K.mean((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"TEM_sample_dataset-{}\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "tensorboard = TensorBoard(log_dir = 'models/{}'.format(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEM_sample_dataset-2019-06-10 19:37:22'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    " model = uconv_net(training_config,  bn_updated_decay = None, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=training_config['learning_rate'], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 1216        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 16) 6416        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512, 512, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 16) 6416        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 32) 4640        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256, 256, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 32) 9248        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 32) 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 256, 32) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 32) 25632       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 32) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 18496       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 64) 36928       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 64)   102464      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  73856       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  409728      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  65664       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64, 64, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 128)  147584      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           dropout_6[0][0]                  \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 64) 36928       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 128, 64) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 32) 128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           dropout_4[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 256, 32) 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 32) 9248        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 256, 32) 128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256, 256, 32) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 32) 0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 16) 2064        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 512, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 32) 0           dropout_2[0][0]                  \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 512, 512, 16) 12816       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 512, 16) 64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 512, 512, 16) 6416        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 512, 16) 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 512, 512, 16) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "finalconv (Conv2D)              (None, 512, 512, 3)  51          dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,557,507\n",
      "Trainable params: 1,554,627\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\", dice_axon, dice_myelin, dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import *\n",
    "from data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/vasha_local/axondeepseg/TEM_striatum/data/Train/'\n",
    "test_path = '/home/vasha_local/axondeepseg/TEM_striatum/data/Validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = training_config[\"n_classes\"]\n",
    "thresholds = training_config[\"thresholds\"]\n",
    "patch_size = training_config[\"trainingset_patchsize\"]\n",
    "\n",
    "batch_size = training_config[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = True # Boolean Value to indicate whether you want to use Data Augmentation or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flipping up-down\n",
      "flipping left-right\n",
      "('height shift: ', 0.158203125, ', width shift: ', 0.083984375)\n",
      "('height shift: ', 0.15234375, ', width shift: ', 0.048828125)\n"
     ]
    }
   ],
   "source": [
    "if(not data_aug):\n",
    "    data_gen_args = dict() \n",
    "else: \n",
    "    data_gen_args = dict(horizontal_flip = flipping()[1],\n",
    "                        vertical_flip = flipping()[0], \n",
    "                        rotation_range = random_rotation()[0], \n",
    "                        width_shift_range = shifting(patch_size, n_classes)[1],\n",
    "                        height_shift_range = shifting(patch_size, n_classes) [0]\n",
    "                        )\n",
    "\n",
    "#Data Augmentation Dictionary for Validation \n",
    "data_gen_args_valid = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'horizontal_flip': True,\n",
       " 'vertical_flip': True,\n",
       " 'rotation_range': 43.73224759795209,\n",
       " 'width_shift_range': 0.083984375,\n",
       " 'height_shift_range': 0.15234375}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Check of augmented data dictionary\n",
    "data_gen_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "train_gen = Generator(batch_size,'/home/vasha_local/axondeepseg/TEM_striatum/data/Train/','images','masks',data_gen_args,save_to_dir = None)\n",
    "valid_gen = Generator(batch_size, '/home/vasha_local/axondeepseg/TEM_striatum/data/Validation/','images','masks', data_gen_args_valid,save_to_dir = None)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps =150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/vasha_local/test_ads/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1000\n",
      "Found 16 images belonging to 1 classes.\n",
      "Found 36 images belonging to 1 classes.\n",
      "Found 16 images belonging to 1 classes.\n",
      "Found 36 images belonging to 1 classes.\n",
      "150/150 [==============================] - 89s 592ms/step - loss: 0.6222 - acc: 0.9159 - dice_axon: 0.0963 - dice_myelin: 0.1316 - dice_coef: 0.5891 - val_loss: 0.3437 - val_acc: 0.9043 - val_dice_axon: 0.3792 - val_dice_myelin: 0.3571 - val_dice_coef: 0.7932\n",
      "Epoch 2/1000\n",
      "150/150 [==============================] - 85s 567ms/step - loss: 0.1648 - acc: 0.9791 - dice_axon: 0.2796 - dice_myelin: 0.3197 - dice_coef: 0.8792 - val_loss: 0.3363 - val_acc: 0.8899 - val_dice_axon: 0.5049 - val_dice_myelin: 0.3567 - val_dice_coef: 0.8677\n",
      "Epoch 3/1000\n",
      "150/150 [==============================] - 85s 567ms/step - loss: 0.0758 - acc: 0.9833 - dice_axon: 0.4741 - dice_myelin: 0.4766 - dice_coef: 0.9489 - val_loss: 0.2189 - val_acc: 0.9397 - val_dice_axon: 0.6816 - val_dice_myelin: 0.6076 - val_dice_coef: 0.9040\n",
      "Epoch 4/1000\n",
      "150/150 [==============================] - 87s 582ms/step - loss: 0.0528 - acc: 0.9856 - dice_axon: 0.5893 - dice_myelin: 0.5585 - dice_coef: 0.9663 - val_loss: 0.1937 - val_acc: 0.9439 - val_dice_axon: 0.7159 - val_dice_myelin: 0.6420 - val_dice_coef: 0.9197\n",
      "Epoch 5/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0499 - acc: 0.9854 - dice_axon: 0.6425 - dice_myelin: 0.5789 - dice_coef: 0.9713 - val_loss: 0.2615 - val_acc: 0.9176 - val_dice_axon: 0.5485 - val_dice_myelin: 0.5742 - val_dice_coef: 0.9030\n",
      "Epoch 6/1000\n",
      "150/150 [==============================] - 85s 565ms/step - loss: 0.0505 - acc: 0.9841 - dice_axon: 0.6421 - dice_myelin: 0.5818 - dice_coef: 0.9715 - val_loss: 0.2943 - val_acc: 0.9191 - val_dice_axon: 0.5810 - val_dice_myelin: 0.5617 - val_dice_coef: 0.9052\n",
      "Epoch 7/1000\n",
      "150/150 [==============================] - 89s 590ms/step - loss: 0.0384 - acc: 0.9870 - dice_axon: 0.7078 - dice_myelin: 0.6239 - dice_coef: 0.9775 - val_loss: 0.1504 - val_acc: 0.9485 - val_dice_axon: 0.7589 - val_dice_myelin: 0.6803 - val_dice_coef: 0.9317\n",
      "Epoch 8/1000\n",
      "150/150 [==============================] - 85s 568ms/step - loss: 0.0364 - acc: 0.9873 - dice_axon: 0.7382 - dice_myelin: 0.6496 - dice_coef: 0.9794 - val_loss: 0.1440 - val_acc: 0.9469 - val_dice_axon: 0.7567 - val_dice_myelin: 0.6717 - val_dice_coef: 0.9327\n",
      "Epoch 9/1000\n",
      "150/150 [==============================] - 90s 599ms/step - loss: 0.0351 - acc: 0.9880 - dice_axon: 0.7457 - dice_myelin: 0.6481 - dice_coef: 0.9805 - val_loss: 0.1291 - val_acc: 0.9517 - val_dice_axon: 0.7714 - val_dice_myelin: 0.6979 - val_dice_coef: 0.9359\n",
      "Epoch 10/1000\n",
      "150/150 [==============================] - 86s 572ms/step - loss: 0.0332 - acc: 0.9880 - dice_axon: 0.7643 - dice_myelin: 0.6613 - dice_coef: 0.9813 - val_loss: 0.1212 - val_acc: 0.9549 - val_dice_axon: 0.7789 - val_dice_myelin: 0.7091 - val_dice_coef: 0.9393\n",
      "Epoch 11/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0352 - acc: 0.9872 - dice_axon: 0.7644 - dice_myelin: 0.6618 - dice_coef: 0.9804 - val_loss: 0.1557 - val_acc: 0.9477 - val_dice_axon: 0.7696 - val_dice_myelin: 0.6810 - val_dice_coef: 0.9356\n",
      "Epoch 12/1000\n",
      "150/150 [==============================] - 87s 581ms/step - loss: 0.0357 - acc: 0.9875 - dice_axon: 0.7683 - dice_myelin: 0.6606 - dice_coef: 0.9810 - val_loss: 0.1361 - val_acc: 0.9512 - val_dice_axon: 0.7838 - val_dice_myelin: 0.7077 - val_dice_coef: 0.9387\n",
      "Epoch 13/1000\n",
      "150/150 [==============================] - 88s 588ms/step - loss: 0.0293 - acc: 0.9890 - dice_axon: 0.7940 - dice_myelin: 0.6907 - dice_coef: 0.9834 - val_loss: 0.1455 - val_acc: 0.9503 - val_dice_axon: 0.7547 - val_dice_myelin: 0.6868 - val_dice_coef: 0.9361\n",
      "Epoch 14/1000\n",
      "150/150 [==============================] - 85s 568ms/step - loss: 0.0302 - acc: 0.9889 - dice_axon: 0.7903 - dice_myelin: 0.6872 - dice_coef: 0.9834 - val_loss: 0.1877 - val_acc: 0.9391 - val_dice_axon: 0.6644 - val_dice_myelin: 0.6737 - val_dice_coef: 0.9224\n",
      "Epoch 15/1000\n",
      "150/150 [==============================] - 88s 584ms/step - loss: 0.0381 - acc: 0.9867 - dice_axon: 0.7559 - dice_myelin: 0.6587 - dice_coef: 0.9806 - val_loss: 0.1404 - val_acc: 0.9499 - val_dice_axon: 0.7872 - val_dice_myelin: 0.6920 - val_dice_coef: 0.9390\n",
      "Epoch 16/1000\n",
      "150/150 [==============================] - 89s 593ms/step - loss: 0.0354 - acc: 0.9877 - dice_axon: 0.7802 - dice_myelin: 0.6743 - dice_coef: 0.9817 - val_loss: 0.2071 - val_acc: 0.9380 - val_dice_axon: 0.7085 - val_dice_myelin: 0.6352 - val_dice_coef: 0.9231\n",
      "Epoch 17/1000\n",
      "150/150 [==============================] - 85s 565ms/step - loss: 0.0276 - acc: 0.9895 - dice_axon: 0.8068 - dice_myelin: 0.7067 - dice_coef: 0.9842 - val_loss: 0.1396 - val_acc: 0.9516 - val_dice_axon: 0.7729 - val_dice_myelin: 0.6920 - val_dice_coef: 0.9358\n",
      "Epoch 18/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0256 - acc: 0.9901 - dice_axon: 0.8181 - dice_myelin: 0.7187 - dice_coef: 0.9852 - val_loss: 0.3190 - val_acc: 0.9235 - val_dice_axon: 0.6521 - val_dice_myelin: 0.5965 - val_dice_coef: 0.9128\n",
      "Epoch 19/1000\n",
      "150/150 [==============================] - 87s 579ms/step - loss: 0.0338 - acc: 0.9880 - dice_axon: 0.7954 - dice_myelin: 0.6849 - dice_coef: 0.9825 - val_loss: 0.1432 - val_acc: 0.9500 - val_dice_axon: 0.7744 - val_dice_myelin: 0.6958 - val_dice_coef: 0.9374\n",
      "Epoch 20/1000\n",
      "150/150 [==============================] - 87s 580ms/step - loss: 0.0276 - acc: 0.9896 - dice_axon: 0.8177 - dice_myelin: 0.7169 - dice_coef: 0.9846 - val_loss: 0.2512 - val_acc: 0.9317 - val_dice_axon: 0.6993 - val_dice_myelin: 0.6258 - val_dice_coef: 0.9203\n",
      "Epoch 21/1000\n",
      "150/150 [==============================] - 84s 562ms/step - loss: 0.0264 - acc: 0.9902 - dice_axon: 0.8229 - dice_myelin: 0.7234 - dice_coef: 0.9856 - val_loss: 0.3123 - val_acc: 0.9255 - val_dice_axon: 0.6690 - val_dice_myelin: 0.5940 - val_dice_coef: 0.9150\n",
      "Epoch 22/1000\n",
      "150/150 [==============================] - 85s 563ms/step - loss: 0.0272 - acc: 0.9901 - dice_axon: 0.8210 - dice_myelin: 0.7241 - dice_coef: 0.9852 - val_loss: 0.1458 - val_acc: 0.9538 - val_dice_axon: 0.7820 - val_dice_myelin: 0.7223 - val_dice_coef: 0.9412\n",
      "Epoch 23/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0277 - acc: 0.9894 - dice_axon: 0.8182 - dice_myelin: 0.7172 - dice_coef: 0.9846 - val_loss: 0.1804 - val_acc: 0.9458 - val_dice_axon: 0.7801 - val_dice_myelin: 0.6963 - val_dice_coef: 0.9372\n",
      "Epoch 24/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0328 - acc: 0.9886 - dice_axon: 0.7992 - dice_myelin: 0.6966 - dice_coef: 0.9834 - val_loss: 0.1517 - val_acc: 0.9510 - val_dice_axon: 0.7644 - val_dice_myelin: 0.7017 - val_dice_coef: 0.9360\n",
      "Epoch 25/1000\n",
      "150/150 [==============================] - 90s 600ms/step - loss: 0.0246 - acc: 0.9906 - dice_axon: 0.8281 - dice_myelin: 0.7340 - dice_coef: 0.9861 - val_loss: 0.1472 - val_acc: 0.9500 - val_dice_axon: 0.7838 - val_dice_myelin: 0.6931 - val_dice_coef: 0.9394\n",
      "Epoch 26/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0256 - acc: 0.9905 - dice_axon: 0.8278 - dice_myelin: 0.7274 - dice_coef: 0.9860 - val_loss: 0.1469 - val_acc: 0.9532 - val_dice_axon: 0.7875 - val_dice_myelin: 0.7290 - val_dice_coef: 0.9444\n",
      "Epoch 27/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0242 - acc: 0.9906 - dice_axon: 0.8338 - dice_myelin: 0.7372 - dice_coef: 0.9863 - val_loss: 0.1425 - val_acc: 0.9506 - val_dice_axon: 0.7997 - val_dice_myelin: 0.7093 - val_dice_coef: 0.9407\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 93s 620ms/step - loss: 0.0231 - acc: 0.9909 - dice_axon: 0.8357 - dice_myelin: 0.7430 - dice_coef: 0.9867 - val_loss: 0.1351 - val_acc: 0.9516 - val_dice_axon: 0.7920 - val_dice_myelin: 0.7099 - val_dice_coef: 0.9425\n",
      "Epoch 29/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0254 - acc: 0.9905 - dice_axon: 0.8318 - dice_myelin: 0.7391 - dice_coef: 0.9862 - val_loss: 0.1829 - val_acc: 0.9450 - val_dice_axon: 0.7221 - val_dice_myelin: 0.7071 - val_dice_coef: 0.9332\n",
      "Epoch 30/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0335 - acc: 0.9880 - dice_axon: 0.7979 - dice_myelin: 0.6964 - dice_coef: 0.9826 - val_loss: 0.1984 - val_acc: 0.9373 - val_dice_axon: 0.6913 - val_dice_myelin: 0.6149 - val_dice_coef: 0.9218\n",
      "Epoch 31/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0324 - acc: 0.9889 - dice_axon: 0.8008 - dice_myelin: 0.6988 - dice_coef: 0.9836 - val_loss: 0.1445 - val_acc: 0.9526 - val_dice_axon: 0.7963 - val_dice_myelin: 0.7207 - val_dice_coef: 0.9406\n",
      "Epoch 32/1000\n",
      "150/150 [==============================] - 93s 623ms/step - loss: 0.0325 - acc: 0.9889 - dice_axon: 0.8141 - dice_myelin: 0.7131 - dice_coef: 0.9839 - val_loss: 0.2760 - val_acc: 0.9268 - val_dice_axon: 0.6402 - val_dice_myelin: 0.6162 - val_dice_coef: 0.9136\n",
      "Epoch 33/1000\n",
      "150/150 [==============================] - 93s 620ms/step - loss: 0.0244 - acc: 0.9908 - dice_axon: 0.8361 - dice_myelin: 0.7410 - dice_coef: 0.9863 - val_loss: 0.1390 - val_acc: 0.9546 - val_dice_axon: 0.7967 - val_dice_myelin: 0.7384 - val_dice_coef: 0.9440\n",
      "Epoch 34/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0217 - acc: 0.9915 - dice_axon: 0.8464 - dice_myelin: 0.7512 - dice_coef: 0.9875 - val_loss: 0.1518 - val_acc: 0.9536 - val_dice_axon: 0.7887 - val_dice_myelin: 0.7225 - val_dice_coef: 0.9413\n",
      "Epoch 35/1000\n",
      "150/150 [==============================] - 93s 623ms/step - loss: 0.0279 - acc: 0.9904 - dice_axon: 0.8373 - dice_myelin: 0.7481 - dice_coef: 0.9860 - val_loss: 0.1645 - val_acc: 0.9503 - val_dice_axon: 0.7663 - val_dice_myelin: 0.7154 - val_dice_coef: 0.9377\n",
      "Epoch 36/1000\n",
      "150/150 [==============================] - 92s 617ms/step - loss: 0.0259 - acc: 0.9909 - dice_axon: 0.8404 - dice_myelin: 0.7482 - dice_coef: 0.9865 - val_loss: 0.1558 - val_acc: 0.9502 - val_dice_axon: 0.7721 - val_dice_myelin: 0.7145 - val_dice_coef: 0.9388\n",
      "Epoch 37/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0246 - acc: 0.9911 - dice_axon: 0.8416 - dice_myelin: 0.7545 - dice_coef: 0.9868 - val_loss: 0.1315 - val_acc: 0.9555 - val_dice_axon: 0.8002 - val_dice_myelin: 0.7366 - val_dice_coef: 0.9458\n",
      "Epoch 38/1000\n",
      "150/150 [==============================] - 91s 610ms/step - loss: 0.0211 - acc: 0.9916 - dice_axon: 0.8515 - dice_myelin: 0.7647 - dice_coef: 0.9877 - val_loss: 0.1555 - val_acc: 0.9523 - val_dice_axon: 0.7773 - val_dice_myelin: 0.7241 - val_dice_coef: 0.9416\n",
      "Epoch 39/1000\n",
      "150/150 [==============================] - 94s 627ms/step - loss: 0.0260 - acc: 0.9912 - dice_axon: 0.8465 - dice_myelin: 0.7650 - dice_coef: 0.9870 - val_loss: 0.1344 - val_acc: 0.9566 - val_dice_axon: 0.7765 - val_dice_myelin: 0.7606 - val_dice_coef: 0.9448\n",
      "Epoch 40/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0235 - acc: 0.9916 - dice_axon: 0.8539 - dice_myelin: 0.7678 - dice_coef: 0.9876 - val_loss: 0.1421 - val_acc: 0.9559 - val_dice_axon: 0.8007 - val_dice_myelin: 0.7585 - val_dice_coef: 0.9471\n",
      "Epoch 41/1000\n",
      "150/150 [==============================] - 93s 621ms/step - loss: 0.0227 - acc: 0.9919 - dice_axon: 0.8553 - dice_myelin: 0.7703 - dice_coef: 0.9880 - val_loss: 0.1852 - val_acc: 0.9442 - val_dice_axon: 0.7597 - val_dice_myelin: 0.7029 - val_dice_coef: 0.9342\n",
      "Epoch 42/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0212 - acc: 0.9921 - dice_axon: 0.8605 - dice_myelin: 0.7811 - dice_coef: 0.9884 - val_loss: 0.2069 - val_acc: 0.9433 - val_dice_axon: 0.7626 - val_dice_myelin: 0.6946 - val_dice_coef: 0.9343\n",
      "Epoch 43/1000\n",
      "150/150 [==============================] - 92s 617ms/step - loss: 0.0212 - acc: 0.9922 - dice_axon: 0.8635 - dice_myelin: 0.7790 - dice_coef: 0.9885 - val_loss: 0.1425 - val_acc: 0.9555 - val_dice_axon: 0.8021 - val_dice_myelin: 0.7487 - val_dice_coef: 0.9479\n",
      "Epoch 44/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0222 - acc: 0.9922 - dice_axon: 0.8626 - dice_myelin: 0.7802 - dice_coef: 0.9885 - val_loss: 0.2129 - val_acc: 0.9439 - val_dice_axon: 0.7620 - val_dice_myelin: 0.7050 - val_dice_coef: 0.9351\n",
      "Epoch 45/1000\n",
      "150/150 [==============================] - 93s 618ms/step - loss: 0.0207 - acc: 0.9920 - dice_axon: 0.8586 - dice_myelin: 0.7774 - dice_coef: 0.9882 - val_loss: 0.1659 - val_acc: 0.9493 - val_dice_axon: 0.7640 - val_dice_myelin: 0.7137 - val_dice_coef: 0.9393\n",
      "Epoch 46/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0260 - acc: 0.9915 - dice_axon: 0.8559 - dice_myelin: 0.7671 - dice_coef: 0.9876 - val_loss: 0.1732 - val_acc: 0.9494 - val_dice_axon: 0.7787 - val_dice_myelin: 0.7247 - val_dice_coef: 0.9395\n",
      "Epoch 47/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0217 - acc: 0.9920 - dice_axon: 0.8585 - dice_myelin: 0.7774 - dice_coef: 0.9881 - val_loss: 0.1500 - val_acc: 0.9528 - val_dice_axon: 0.8009 - val_dice_myelin: 0.7358 - val_dice_coef: 0.9430\n",
      "Epoch 48/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0196 - acc: 0.9928 - dice_axon: 0.8657 - dice_myelin: 0.7903 - dice_coef: 0.9893 - val_loss: 0.1605 - val_acc: 0.9524 - val_dice_axon: 0.7976 - val_dice_myelin: 0.7528 - val_dice_coef: 0.9455\n",
      "Epoch 49/1000\n",
      "150/150 [==============================] - 95s 631ms/step - loss: 0.0190 - acc: 0.9930 - dice_axon: 0.8739 - dice_myelin: 0.7973 - dice_coef: 0.9897 - val_loss: 0.1858 - val_acc: 0.9469 - val_dice_axon: 0.7880 - val_dice_myelin: 0.7044 - val_dice_coef: 0.9395\n",
      "Epoch 50/1000\n",
      "150/150 [==============================] - 92s 613ms/step - loss: 0.0206 - acc: 0.9929 - dice_axon: 0.8728 - dice_myelin: 0.7942 - dice_coef: 0.9895 - val_loss: 0.1488 - val_acc: 0.9553 - val_dice_axon: 0.8137 - val_dice_myelin: 0.7694 - val_dice_coef: 0.9491\n",
      "Epoch 51/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0200 - acc: 0.9929 - dice_axon: 0.8701 - dice_myelin: 0.7913 - dice_coef: 0.9895 - val_loss: 0.1547 - val_acc: 0.9531 - val_dice_axon: 0.8085 - val_dice_myelin: 0.7533 - val_dice_coef: 0.9467\n",
      "Epoch 52/1000\n",
      "150/150 [==============================] - 94s 627ms/step - loss: 0.0196 - acc: 0.9932 - dice_axon: 0.8741 - dice_myelin: 0.8060 - dice_coef: 0.9898 - val_loss: 0.1578 - val_acc: 0.9544 - val_dice_axon: 0.7998 - val_dice_myelin: 0.7587 - val_dice_coef: 0.9464\n",
      "Epoch 53/1000\n",
      "150/150 [==============================] - 91s 610ms/step - loss: 0.0196 - acc: 0.9925 - dice_axon: 0.8726 - dice_myelin: 0.7949 - dice_coef: 0.9891 - val_loss: 0.1373 - val_acc: 0.9536 - val_dice_axon: 0.8031 - val_dice_myelin: 0.7508 - val_dice_coef: 0.9454\n",
      "Epoch 54/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0491 - acc: 0.9840 - dice_axon: 0.7253 - dice_myelin: 0.6189 - dice_coef: 0.9770 - val_loss: 1.5983 - val_acc: 0.7524 - val_dice_axon: 0.1194 - val_dice_myelin: 0.1393 - val_dice_coef: 0.7542\n",
      "Epoch 55/1000\n",
      "150/150 [==============================] - 95s 632ms/step - loss: 0.0290 - acc: 0.9893 - dice_axon: 0.8070 - dice_myelin: 0.7082 - dice_coef: 0.9843 - val_loss: 0.1637 - val_acc: 0.9486 - val_dice_axon: 0.7754 - val_dice_myelin: 0.7106 - val_dice_coef: 0.9400\n",
      "Epoch 56/1000\n",
      "150/150 [==============================] - 93s 622ms/step - loss: 0.0266 - acc: 0.9904 - dice_axon: 0.8244 - dice_myelin: 0.7332 - dice_coef: 0.9858 - val_loss: 0.1339 - val_acc: 0.9561 - val_dice_axon: 0.7980 - val_dice_myelin: 0.7539 - val_dice_coef: 0.9457\n",
      "Epoch 57/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0254 - acc: 0.9909 - dice_axon: 0.8401 - dice_myelin: 0.7518 - dice_coef: 0.9866 - val_loss: 0.1355 - val_acc: 0.9560 - val_dice_axon: 0.7992 - val_dice_myelin: 0.7528 - val_dice_coef: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "150/150 [==============================] - 88s 586ms/step - loss: 0.0194 - acc: 0.9923 - dice_axon: 0.8559 - dice_myelin: 0.7772 - dice_coef: 0.9887 - val_loss: 0.2782 - val_acc: 0.9390 - val_dice_axon: 0.6845 - val_dice_myelin: 0.7103 - val_dice_coef: 0.9319\n",
      "Epoch 59/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0205 - acc: 0.9923 - dice_axon: 0.8595 - dice_myelin: 0.7806 - dice_coef: 0.9887 - val_loss: 0.1675 - val_acc: 0.9478 - val_dice_axon: 0.7700 - val_dice_myelin: 0.7219 - val_dice_coef: 0.9383\n",
      "Epoch 60/1000\n",
      "150/150 [==============================] - 94s 623ms/step - loss: 0.0242 - acc: 0.9919 - dice_axon: 0.8560 - dice_myelin: 0.7793 - dice_coef: 0.9882 - val_loss: 0.1594 - val_acc: 0.9524 - val_dice_axon: 0.8116 - val_dice_myelin: 0.7480 - val_dice_coef: 0.9464\n",
      "Epoch 61/1000\n",
      "150/150 [==============================] - 92s 612ms/step - loss: 0.0233 - acc: 0.9921 - dice_axon: 0.8603 - dice_myelin: 0.7809 - dice_coef: 0.9882 - val_loss: 0.1667 - val_acc: 0.9533 - val_dice_axon: 0.8010 - val_dice_myelin: 0.7584 - val_dice_coef: 0.9474\n",
      "Epoch 62/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0189 - acc: 0.9928 - dice_axon: 0.8687 - dice_myelin: 0.7947 - dice_coef: 0.9894 - val_loss: 0.1481 - val_acc: 0.9562 - val_dice_axon: 0.8050 - val_dice_myelin: 0.7727 - val_dice_coef: 0.9484\n",
      "Epoch 63/1000\n",
      "150/150 [==============================] - 93s 617ms/step - loss: 0.0193 - acc: 0.9930 - dice_axon: 0.8685 - dice_myelin: 0.7937 - dice_coef: 0.9896 - val_loss: 0.1739 - val_acc: 0.9496 - val_dice_axon: 0.7846 - val_dice_myelin: 0.7402 - val_dice_coef: 0.9439\n",
      "Epoch 64/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0210 - acc: 0.9928 - dice_axon: 0.8700 - dice_myelin: 0.7972 - dice_coef: 0.9893 - val_loss: 0.1640 - val_acc: 0.9531 - val_dice_axon: 0.7960 - val_dice_myelin: 0.7537 - val_dice_coef: 0.9454\n",
      "Epoch 65/1000\n",
      "150/150 [==============================] - 90s 601ms/step - loss: 0.0169 - acc: 0.9936 - dice_axon: 0.8853 - dice_myelin: 0.8170 - dice_coef: 0.9905 - val_loss: 0.2038 - val_acc: 0.9466 - val_dice_axon: 0.7835 - val_dice_myelin: 0.7133 - val_dice_coef: 0.9390\n",
      "Epoch 66/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0182 - acc: 0.9934 - dice_axon: 0.8812 - dice_myelin: 0.8089 - dice_coef: 0.9903 - val_loss: 0.1807 - val_acc: 0.9478 - val_dice_axon: 0.7876 - val_dice_myelin: 0.7176 - val_dice_coef: 0.9415\n",
      "Epoch 67/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0187 - acc: 0.9934 - dice_axon: 0.8838 - dice_myelin: 0.8148 - dice_coef: 0.9902 - val_loss: 0.1776 - val_acc: 0.9497 - val_dice_axon: 0.7949 - val_dice_myelin: 0.7238 - val_dice_coef: 0.9444\n",
      "Epoch 68/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0158 - acc: 0.9940 - dice_axon: 0.8885 - dice_myelin: 0.8216 - dice_coef: 0.9911 - val_loss: 0.1821 - val_acc: 0.9497 - val_dice_axon: 0.7904 - val_dice_myelin: 0.7380 - val_dice_coef: 0.9430\n",
      "Epoch 69/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0171 - acc: 0.9938 - dice_axon: 0.8890 - dice_myelin: 0.8224 - dice_coef: 0.9909 - val_loss: 0.1720 - val_acc: 0.9528 - val_dice_axon: 0.8161 - val_dice_myelin: 0.7608 - val_dice_coef: 0.9478\n",
      "Epoch 70/1000\n",
      "150/150 [==============================] - 91s 604ms/step - loss: 0.0194 - acc: 0.9927 - dice_axon: 0.8739 - dice_myelin: 0.8010 - dice_coef: 0.9894 - val_loss: 0.1759 - val_acc: 0.9496 - val_dice_axon: 0.7847 - val_dice_myelin: 0.7311 - val_dice_coef: 0.9420\n",
      "Epoch 71/1000\n",
      "150/150 [==============================] - 91s 607ms/step - loss: 0.0174 - acc: 0.9935 - dice_axon: 0.8842 - dice_myelin: 0.8141 - dice_coef: 0.9904 - val_loss: 0.1755 - val_acc: 0.9515 - val_dice_axon: 0.7984 - val_dice_myelin: 0.7440 - val_dice_coef: 0.9464\n",
      "Epoch 72/1000\n",
      "150/150 [==============================] - 92s 611ms/step - loss: 0.0170 - acc: 0.9939 - dice_axon: 0.8897 - dice_myelin: 0.8196 - dice_coef: 0.9910 - val_loss: 0.1730 - val_acc: 0.9528 - val_dice_axon: 0.8075 - val_dice_myelin: 0.7585 - val_dice_coef: 0.9479\n",
      "Epoch 73/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0169 - acc: 0.9939 - dice_axon: 0.8891 - dice_myelin: 0.8230 - dice_coef: 0.9909 - val_loss: 0.1810 - val_acc: 0.9495 - val_dice_axon: 0.7936 - val_dice_myelin: 0.7393 - val_dice_coef: 0.9444\n",
      "Epoch 74/1000\n",
      "150/150 [==============================] - 91s 606ms/step - loss: 0.0194 - acc: 0.9936 - dice_axon: 0.8882 - dice_myelin: 0.8236 - dice_coef: 0.9904 - val_loss: 0.2065 - val_acc: 0.9461 - val_dice_axon: 0.7784 - val_dice_myelin: 0.7204 - val_dice_coef: 0.9416\n",
      "Epoch 75/1000\n",
      "150/150 [==============================] - 91s 608ms/step - loss: 0.0171 - acc: 0.9939 - dice_axon: 0.8900 - dice_myelin: 0.8207 - dice_coef: 0.9909 - val_loss: 0.1624 - val_acc: 0.9530 - val_dice_axon: 0.7913 - val_dice_myelin: 0.7636 - val_dice_coef: 0.9460\n",
      "Epoch 76/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0194 - acc: 0.9935 - dice_axon: 0.8862 - dice_myelin: 0.8176 - dice_coef: 0.9902 - val_loss: 0.2083 - val_acc: 0.9450 - val_dice_axon: 0.7708 - val_dice_myelin: 0.7239 - val_dice_coef: 0.9376\n",
      "Epoch 77/1000\n",
      "150/150 [==============================] - 94s 625ms/step - loss: 0.0164 - acc: 0.9942 - dice_axon: 0.8929 - dice_myelin: 0.8295 - dice_coef: 0.9913 - val_loss: 0.2006 - val_acc: 0.9468 - val_dice_axon: 0.7785 - val_dice_myelin: 0.7344 - val_dice_coef: 0.9404\n",
      "Epoch 78/1000\n",
      "150/150 [==============================] - 92s 614ms/step - loss: 0.0201 - acc: 0.9936 - dice_axon: 0.8916 - dice_myelin: 0.8238 - dice_coef: 0.9905 - val_loss: 0.1776 - val_acc: 0.9506 - val_dice_axon: 0.7922 - val_dice_myelin: 0.7565 - val_dice_coef: 0.9443\n",
      "Epoch 79/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0174 - acc: 0.9942 - dice_axon: 0.8930 - dice_myelin: 0.8336 - dice_coef: 0.9913 - val_loss: 0.1883 - val_acc: 0.9504 - val_dice_axon: 0.7991 - val_dice_myelin: 0.7449 - val_dice_coef: 0.9464\n",
      "Epoch 80/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0181 - acc: 0.9939 - dice_axon: 0.8923 - dice_myelin: 0.8250 - dice_coef: 0.9909 - val_loss: 0.1603 - val_acc: 0.9520 - val_dice_axon: 0.8002 - val_dice_myelin: 0.7537 - val_dice_coef: 0.9463\n",
      "Epoch 81/1000\n",
      "150/150 [==============================] - 90s 602ms/step - loss: 0.0189 - acc: 0.9939 - dice_axon: 0.8960 - dice_myelin: 0.8308 - dice_coef: 0.9909 - val_loss: 0.1974 - val_acc: 0.9479 - val_dice_axon: 0.7867 - val_dice_myelin: 0.7466 - val_dice_coef: 0.9421\n",
      "Epoch 82/1000\n",
      "150/150 [==============================] - 90s 603ms/step - loss: 0.0171 - acc: 0.9937 - dice_axon: 0.8866 - dice_myelin: 0.8195 - dice_coef: 0.9906 - val_loss: 0.1743 - val_acc: 0.9497 - val_dice_axon: 0.7803 - val_dice_myelin: 0.7341 - val_dice_coef: 0.9421\n",
      "Epoch 83/1000\n",
      "150/150 [==============================] - 92s 610ms/step - loss: 0.0221 - acc: 0.9930 - dice_axon: 0.8798 - dice_myelin: 0.8109 - dice_coef: 0.9895 - val_loss: 0.1924 - val_acc: 0.9470 - val_dice_axon: 0.7914 - val_dice_myelin: 0.7353 - val_dice_coef: 0.9422\n",
      "Epoch 84/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0148 - acc: 0.9946 - dice_axon: 0.8973 - dice_myelin: 0.8395 - dice_coef: 0.9918 - val_loss: 0.1738 - val_acc: 0.9523 - val_dice_axon: 0.8096 - val_dice_myelin: 0.7534 - val_dice_coef: 0.9483\n",
      "Epoch 85/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0182 - acc: 0.9940 - dice_axon: 0.8951 - dice_myelin: 0.8370 - dice_coef: 0.9911 - val_loss: 0.1871 - val_acc: 0.9498 - val_dice_axon: 0.7846 - val_dice_myelin: 0.7385 - val_dice_coef: 0.9442\n",
      "Epoch 86/1000\n",
      "150/150 [==============================] - 90s 603ms/step - loss: 0.0148 - acc: 0.9946 - dice_axon: 0.9026 - dice_myelin: 0.8458 - dice_coef: 0.9919 - val_loss: 0.1749 - val_acc: 0.9523 - val_dice_axon: 0.7991 - val_dice_myelin: 0.7605 - val_dice_coef: 0.9471\n",
      "Epoch 87/1000\n",
      "150/150 [==============================] - 91s 604ms/step - loss: 0.0174 - acc: 0.9939 - dice_axon: 0.8933 - dice_myelin: 0.8277 - dice_coef: 0.9910 - val_loss: 0.1717 - val_acc: 0.9521 - val_dice_axon: 0.8027 - val_dice_myelin: 0.7545 - val_dice_coef: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/1000\n",
      "150/150 [==============================] - 91s 609ms/step - loss: 0.0149 - acc: 0.9945 - dice_axon: 0.9014 - dice_myelin: 0.8436 - dice_coef: 0.9919 - val_loss: 0.1923 - val_acc: 0.9486 - val_dice_axon: 0.7902 - val_dice_myelin: 0.7332 - val_dice_coef: 0.9434\n",
      "Epoch 89/1000\n",
      "150/150 [==============================] - 92s 611ms/step - loss: 0.0137 - acc: 0.9949 - dice_axon: 0.9057 - dice_myelin: 0.8474 - dice_coef: 0.9924 - val_loss: 0.1804 - val_acc: 0.9514 - val_dice_axon: 0.8057 - val_dice_myelin: 0.7553 - val_dice_coef: 0.9470\n",
      "Epoch 90/1000\n",
      "150/150 [==============================] - 91s 605ms/step - loss: 0.0166 - acc: 0.9944 - dice_axon: 0.9044 - dice_myelin: 0.8463 - dice_coef: 0.9917 - val_loss: 0.1855 - val_acc: 0.9499 - val_dice_axon: 0.8003 - val_dice_myelin: 0.7456 - val_dice_coef: 0.9457\n",
      "Epoch 91/1000\n",
      "150/150 [==============================] - 84s 563ms/step - loss: 0.0140 - acc: 0.9950 - dice_axon: 0.9101 - dice_myelin: 0.8522 - dice_coef: 0.9926 - val_loss: 0.2225 - val_acc: 0.9433 - val_dice_axon: 0.7766 - val_dice_myelin: 0.7167 - val_dice_coef: 0.9378\n",
      "Epoch 92/1000\n",
      "150/150 [==============================] - 87s 580ms/step - loss: 0.0118 - acc: 0.9954 - dice_axon: 0.9179 - dice_myelin: 0.8644 - dice_coef: 0.9932 - val_loss: 0.1903 - val_acc: 0.9533 - val_dice_axon: 0.8123 - val_dice_myelin: 0.7681 - val_dice_coef: 0.9502\n",
      "Epoch 93/1000\n",
      "150/150 [==============================] - 90s 598ms/step - loss: 0.0162 - acc: 0.9945 - dice_axon: 0.9081 - dice_myelin: 0.8548 - dice_coef: 0.9919 - val_loss: 0.1702 - val_acc: 0.9501 - val_dice_axon: 0.8001 - val_dice_myelin: 0.7441 - val_dice_coef: 0.9440\n",
      "Epoch 94/1000\n",
      "150/150 [==============================] - 85s 566ms/step - loss: 0.0140 - acc: 0.9949 - dice_axon: 0.9069 - dice_myelin: 0.8520 - dice_coef: 0.9924 - val_loss: 0.1867 - val_acc: 0.9501 - val_dice_axon: 0.8136 - val_dice_myelin: 0.7517 - val_dice_coef: 0.9468\n",
      "Epoch 95/1000\n",
      "150/150 [==============================] - 86s 572ms/step - loss: 0.0129 - acc: 0.9951 - dice_axon: 0.9128 - dice_myelin: 0.8585 - dice_coef: 0.9927 - val_loss: 0.1755 - val_acc: 0.9517 - val_dice_axon: 0.8035 - val_dice_myelin: 0.7461 - val_dice_coef: 0.9476\n",
      "Epoch 96/1000\n",
      "150/150 [==============================] - 88s 590ms/step - loss: 0.0130 - acc: 0.9952 - dice_axon: 0.9151 - dice_myelin: 0.8628 - dice_coef: 0.9930 - val_loss: 0.1811 - val_acc: 0.9528 - val_dice_axon: 0.8136 - val_dice_myelin: 0.7681 - val_dice_coef: 0.9495\n",
      "Epoch 97/1000\n",
      "150/150 [==============================] - 86s 576ms/step - loss: 0.0119 - acc: 0.9953 - dice_axon: 0.9178 - dice_myelin: 0.8676 - dice_coef: 0.9931 - val_loss: 0.1764 - val_acc: 0.9544 - val_dice_axon: 0.8179 - val_dice_myelin: 0.7800 - val_dice_coef: 0.9508\n",
      "Epoch 98/1000\n",
      "150/150 [==============================] - 87s 578ms/step - loss: 0.0128 - acc: 0.9952 - dice_axon: 0.9173 - dice_myelin: 0.8633 - dice_coef: 0.9930 - val_loss: 0.2019 - val_acc: 0.9489 - val_dice_axon: 0.7936 - val_dice_myelin: 0.7497 - val_dice_coef: 0.9447\n",
      "Epoch 99/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0148 - acc: 0.9949 - dice_axon: 0.9082 - dice_myelin: 0.8534 - dice_coef: 0.9925 - val_loss: 0.1885 - val_acc: 0.9516 - val_dice_axon: 0.8167 - val_dice_myelin: 0.7653 - val_dice_coef: 0.9485\n",
      "Epoch 100/1000\n",
      "150/150 [==============================] - 88s 584ms/step - loss: 0.0134 - acc: 0.9951 - dice_axon: 0.9143 - dice_myelin: 0.8613 - dice_coef: 0.9927 - val_loss: 0.2183 - val_acc: 0.9467 - val_dice_axon: 0.7720 - val_dice_myelin: 0.7246 - val_dice_coef: 0.9409\n",
      "Epoch 101/1000\n",
      "150/150 [==============================] - 87s 581ms/step - loss: 0.0164 - acc: 0.9945 - dice_axon: 0.9076 - dice_myelin: 0.8490 - dice_coef: 0.9920 - val_loss: 0.1637 - val_acc: 0.9555 - val_dice_axon: 0.8236 - val_dice_myelin: 0.7795 - val_dice_coef: 0.9515\n",
      "Epoch 102/1000\n",
      "150/150 [==============================] - 90s 597ms/step - loss: 0.0124 - acc: 0.9952 - dice_axon: 0.9137 - dice_myelin: 0.8607 - dice_coef: 0.9928 - val_loss: 0.1876 - val_acc: 0.9524 - val_dice_axon: 0.8113 - val_dice_myelin: 0.7719 - val_dice_coef: 0.9493\n",
      "Epoch 103/1000\n",
      "150/150 [==============================] - 86s 574ms/step - loss: 0.0162 - acc: 0.9946 - dice_axon: 0.9017 - dice_myelin: 0.8433 - dice_coef: 0.9921 - val_loss: 0.1740 - val_acc: 0.9541 - val_dice_axon: 0.8092 - val_dice_myelin: 0.7702 - val_dice_coef: 0.9493\n",
      "Epoch 104/1000\n",
      "150/150 [==============================] - 86s 571ms/step - loss: 0.0130 - acc: 0.9954 - dice_axon: 0.9125 - dice_myelin: 0.8626 - dice_coef: 0.9931 - val_loss: 0.1761 - val_acc: 0.9537 - val_dice_axon: 0.8168 - val_dice_myelin: 0.7715 - val_dice_coef: 0.9500\n",
      "Epoch 105/1000\n",
      "115/150 [======================>.......] - ETA: 20s - loss: 0.0130 - acc: 0.9953 - dice_axon: 0.9132 - dice_myelin: 0.8606 - dice_coef: 0.9931"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen, validation_data = valid_gen, steps_per_epoch=train_steps, validation_steps = 2,\n",
    "                    epochs= 1000,  callbacks = [tensorboard])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Weights\n",
    "model.save_weights(\"TEM_sample_Model.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Ground Truth\n",
    "plt.imshow(y[7,:,:,2], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result[7,:,:,2], cmap = \"gray\") # Predicted Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo - Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''# Modify the lines below to use your image\n",
    "path_img = Path(\"./TEM_striatum/data/Testing\")\n",
    "file_img = \"image_819.png\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-29-ab792477a621>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-ab792477a621>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    prediction = axon_segmentation(path_img, file_img, path_model, config_network, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)\u001b[0m\n\u001b[0m                                                                                                                                                           \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''# In case you want to test the segmentation with a pre-trained model created using this notebook,\n",
    "# uncomment the line below.\n",
    "path_model = Path(\"./TEM_striatum/model/TEM_3c_512_2018-11-10_21-32-36/\")\n",
    "\n",
    "# reset the tensorflow graph for new testing\n",
    "tf.reset_default_graph()\n",
    "prediction = axon_segmentation(path_img, file_img, path_model, config_network, acquired_resolution=0.01, resampled_resolutions=0.01, verbosity_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-30-da19f92788a1>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-da19f92788a1>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    plt.show()\u001b[0m\n\u001b[0m              \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''file_img_seg = 'AxonDeepSeg.png'  # axon+myelin segmentation\n",
    "\n",
    "img_seg = imageio.imread(path_img / file_img_seg)\n",
    "img = imageio.imread(path_img / file_img)\n",
    "# Note: The arguments of the two function calls above use the pathlib syntax for path concatenation.\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(13,10))\n",
    "ax1, ax2 = axes[0], axes[1]\n",
    "ax1.set_title('Original image')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Prediction with the trained model')\n",
    "ax2.imshow(img_seg,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
